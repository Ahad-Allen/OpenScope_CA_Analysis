'''
file_util.py

This module contains functions for dealing with reading and writing of data files 
generated by the AIBS experiments for the Credit Assignment Project.

Authors: Blake Richards

Date: August, 2018

Note: this code uses python 2.7.

'''

import os.path
import exceptions

import pandas as pd
import pickle
import json

import gen_util


###############################################################################
def add_ext(file_name, file_type='pickle'):
    '''
    add_ext(file_name)

    Adds an extension to a file_name if it is not included. Only adds pickle,
    json or csv extensions.
 
    Required arguments:
        - file_name (str): name of file, can include the whole directory name
                           and extension
    
    Optional arguments:
        - file_type (str): type of file (pickle, pkl, json, csv)
                           default: 'pickle'

    Outputs:
        - file_name (str): file name, including extension
        - ext (str)      : extension, including '.'
    '''

    _, ext = os.path.splitext(file_name)

    if ext == '':
        file_types = ['pkl', 'pickle', 'json', 'csv']
        file_exts  = ['.pkl', '.pkl', '.json', '.csv']
        if file_type not in file_types:
            gen_util.accepted_values_error('file_type', file_type, file_types)
        ext = file_exts[file_types.index(file_type)]
        file_name = '{}{}'.format(file_name, ext)
    
    return file_name, ext


###############################################################################
def load_file(file_name, full_dir='.', file_type='pickle'):
    '''
    load_file(filename)

    Safely opens and loads a pickle or pandas dataframe. If the file name 
    includes the extension, it will override the file_type argument. 
 
    Required arguments:
        - file_name (str): name of file, can include the whole directory name
                           and extension
    
    Optional arguments:
        - full_dir (str) : directory in which file is saed
                           default: '.'
        - file_type (str): type of file (pickle, pkl, json, csv)
                           default: 'pickle'

    Outputs:
        - datafile (dict or pd df): loaded file
    '''

    file_name, ext = add_ext(file_name, file_type)
    full_name = os.path.join(full_dir, file_name)
    
    if os.path.exists(full_name):
        if ext == '.pkl':
            with open(full_name, 'rb') as f:
                datafile = pickle.load(f)
        elif ext == '.json':
            with open(full_name, 'rb') as f:
                datafile = json.load(f)
        elif ext == '.csv':
            datafile = pd.read_csv(full_name)
    else:
        raise IOError('{} does not exist.'.format(full_name))

    return datafile


#############################################
def save_info(save_obj, save_name='info', full_dir='.', save_as='pickle', 
              sort=True):
    '''
    save_info(dict, full_dir)

    Pickles and saves dictionary under a specific directory and optional name.
    If save_name includes the extension, it will override the save_as argument.

    Required arguments:
        - save_obj (dict): object to save
    
    Optional arguments:
        - full_dir (str) : directory in which to save pickle
                           default: '.'
        - save_name (str): name under which to save info, can include the 
                           whole directory name and extension
                           default: 'info'
        - save_as (str)  : type of file to save as (pickle, pkl, json, csv)
                           default: 'pickle'
        - sort (bool)    : whether to sort keys alphabetically, if saving a 
                           dictionary as .json
                           default: True
    '''

    save_name, ext = add_ext(save_name, save_as)
    full_name = os.path.join(full_dir, save_name)

    # create directory if it doesn't exist
    if not os.path.exists(full_dir):
        os.makedirs(full_dir)
    
    if ext == '.pkl':
        with open(full_name, 'wb') as f:
            pickle.dump(save_obj, f)
    elif ext == '.json':
        with open(full_name, 'w') as f:
            json.dump(save_obj, f, sort_keys=sort)
    elif ext == '.csv':
        save_obj.to_csv(full_name)


#############################################
def create_dir(dirname, unique=True, print_dir=True):
    '''
    create_dir(filename)

    Creates a specified directory if it does not exist.
 
    Required arguments:
        - dirname (string or list): path or hierarchical list of directories, 
                                    e.g. ['dir', 'subdir', 'subsubdir']

    Optional arguments:
        - unique (bool)   : if True, ensures that a new directory is created by  
                            adding a suffix, e.g. '_1' if necessary
                            default: True
        - print_dir (bool): if True, the name of the created directory is 
                            printed

    Outputs:
        - dirname (string): name of new directory
    '''
    # convert directory list to full path
    dirname = os.path.join(*gen_util.list_if_not(dirname))

    if unique and os.path.exists(dirname):
        i=1
        while os.path.exists('{}_{}'.format(dirname, i)):
            i += 1
        dirname = '{}_{}'.format(dirname, i)
        os.makedirs(dirname)
    else:
        os.makedirs(dirname)

    if print_dir:
        print('Directory: {}'.format(dirname))

    return dirname


###############################################################################
def check_datadir(datadir):
    '''
    check_datadir(datadir)

    Checks whether the specified data directory exists and conforms to the
    expected AIBS structure for a session.
 
    Required arguments:
        - data_directory (string)    : name of the data directory

    Outputs:
        - dirokay (boolean): true is structure is okay, false is not
                             Note: if the directory doesn't exist
                             a FILE_NOT_FOUND_ERROR exception is raised
    '''

    # check that the directory exists
    if not os.path.isdir(datadir):
        raise exceptions.OSError(('{} either does not exist or is not a '
                                  'directory').format(datadir))
    else:
        dirokay = True

    # TO-DO: ACTUALLY CHECK THE DIRECTORY STRUCTURE, MAKES SURE IT CONFORMS TO 
    # EXPECTED

    return dirokay

###############################################################################
def get_file_names(masterdir, session, experiment, date, mouse, runtype='prod'):
    '''
    get_file_names(main_directory, session, experiment, date, mouse)

    Gets the full path names of all of the expected data files in the 
    main_directory for the specified session and experiment on the given date 
    that can be used for the Credit Assignment analysis.
 
    Required arguments:
        - main_directory (string)    : name of the master data directory
        - session (string)           : string for the session ID (9 digits)
                                       e.g. '712483302'
        - experiment (string)        : string for the experiment ID (9 digits)
                                       e.g. '715925563'
        - date (string)              : date for the session in YYYYMMDD
                                       e.g. '20160802'
        - mouse (string)             : mouse 6-digit ID string used for session
                                       files
                                       e.g. '389778' 
                                       TO-DO: RENAME LATER

    Outputs:
        - experiment_dir (string): full path name of the experiment directory
        - processed_dir (string) : full path name of the processed data directory
        - stim_pkl_file  (string): full path name of the stimulus
                                   pickle file
        - stim_sync_file (string): full path name of the stimulus
                                   synchronization hdf5 file
        - align_pkl_file (string): full path name of the stimulus
                                   alignment pickle file
        - corrected_data (string): full path name of the motion
                                   corrected 2p data hdf5 file
        - roi_trace_data (string): full path name of the ROI F trace data file
        - zstack (string)        : full path name of the zstack
                                   2p file from the session
    '''
    
    # get the name of the session and experiment data directories
    if runtype == 'pilot':
        sessiondir    = os.path.join(masterdir, 'ophys_session_{}'.format(session))
    elif runtype == 'prod':
        sessiondir    = os.path.join(masterdir, 'mouse_{}'.format(mouse), 
                                     'ophys_session_{}'.format(session))
    experimentdir = os.path.join(sessiondir, 'ophys_experiment_{}'.format(experiment))
    processeddir = os.path.join(experimentdir, 'processed')

    # check the directory 
    if check_datadir(sessiondir):

        # set the file names
        stim_pkl_file  = os.path.join(sessiondir, '{}_{}_{}_stim.pkl'.format(session, mouse, date))
        stim_sync_file = os.path.join(sessiondir, '{}_{}_{}_sync.h5'.format(session, mouse, date))
        align_pkl_file = os.path.join(sessiondir, '{}_{}_{}_df.pkl'.format(session, mouse, date))
        corrected_data = os.path.join(processeddir, 'concat_31Hz_0.h5')
        roi_trace_data = os.path.join(processeddir, 'roi_traces.h5')
        roi_trace_dff  = os.path.join(processeddir, 'roi_traces_dff.h5')
        zstack         = os.path.join(sessiondir, '{}_zstack_column.h5'.format(session))

        # double check that the files actually exist
        if not os.path.isfile(stim_pkl_file):
            raise exceptions.OSError('{} does not exist'.format(stim_pkl_file))
        if not os.path.isfile(stim_sync_file):
            raise exceptions.OSError('{} does not exist'.format(stim_sync_file))
        #if not os.path.isfile(corrected_data): ADD THIS BACK LATER...
        #    raise exceptions.OSError('{} does not exist'.format(corrected_data))
        if not os.path.isfile(roi_trace_data):
            raise exceptions.OSError('{} does not exist'.format(roi_trace_data))
        #if not os.path.isfile(zstack): ADD THIS BACK LATER...
        #    raise exceptions.OSError('{} does not exist'.format(zstack))

        # TO-DO: ADD OTHER KEY FILES

    else:
        raise exceptions.UserWarning(('{} does not conform to expected AIBS '
                                      'structure').format(sessiondir))

    return (experimentdir, processeddir, stim_pkl_file, stim_sync_file, 
            align_pkl_file, corrected_data, roi_trace_data, roi_trace_dff, 
            zstack)


###############################################################################
def get_files(direc='.', file_type='all', criteria=None):
    '''
    get_files()

    Gets all files in given directory.

    Optional arguments:
        - diriec (str    : directory
        - file_type (str): type of file to return: 'all', 'subdirs' or 'files'
                           default: 'all'
        - criteria (str) : criteria for including files, i.e., contains 
                           specified string
                           default: None

    Outputs:
        - files (list): list of files in directory
    '''

    all_files = os.listdir(direc)

    if criteria is not None:
        all_files = [x for x in all_files if criteria in x]
    
    all_files = [os.path.join(direc, x) for x in all_files]

    if file_type == 'subdirs':
        all_files = [x for x in all_files if os.path.isdir(x)]

    elif file_type == 'files':
        all_files = [x for x in all_files if not os.path.isdir(x)]

    elif file_type != 'all':
        gen_util.accepted_values_error('file_type', file_type, ['all', 
                                       'subdirs', 'files'])
    
    return all_files

    