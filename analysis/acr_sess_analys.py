"""
acr_sess_analys.py

This script runs analyses across sessions using a Session object with data 
generated by the AIBS experiments for the Credit Assignment Project.

Authors: Colleen Gillon

Date: October, 2019

Note: this code uses python 3.7.

"""

import copy

from joblib import Parallel, delayed
import numpy as np
import scipy.stats as scist

from . import pup_analys, ori_analys, quint_analys, signif_grps
from util import file_util, gen_util, math_util
from sess_util import sess_gen_util, sess_ntuple_util, sess_str_util
from plot_fcts import acr_sess_analysis_plots as acr_sess_plots



#############################################
def split_by_linpla(sessions, rem_empty=False):
    """
    split_by_linpla(sessions)

    Returns nested list of sessions organized by line/plane.

    Required args:
        - sessions (list): nested list of Session objects (mouse x sess)

    Optional args:
        - rem_empty (bool): if True, line/planes with no sessions are omitted
                            default: False

    Returns:
        - linpla_sess (list) : nested list of Session objects 
                               (linpla x mouse x sess) (None for missing 
                               sessions)
        - linpla_order (list): line x plane order
    """

    lines   = ['L2/3', 'L5']
    planes  = ['dendrites', 'soma']
    linpla_order = [f'{lin} {pla[:4]}' for pla in planes for lin in lines]
    linpla_strip = [s.replace('/', '') for s in linpla_order]
    
    linpla_sess = [[] for _ in range(len(linpla_order))] # linpla x mice x sess
    for mouse_sess in sessions:
        line = list(set([sess.line for sess in mouse_sess if sess is not None]))
        if len(line) != 1:
            raise ValueError('Error - why multiple lines? (or None?)')
        else:
            line = line[0][:3].strip('-')
        
        plas = [sess.plane for sess in mouse_sess if sess is not None]
        pla_vals = list(set(plas))

        for pla in pla_vals:
            sesses = []
            for sess in mouse_sess:
                if sess is None or sess.plane != pla:
                    sesses.append(None)
                else:
                    sesses.append(sess)             
            if list(set(sesses)) != [None]: # only add if it's not all None
                idx = linpla_strip.index(f'{line} {pla}')
                linpla_sess[idx].append(sesses)

    # check for empty lists in any lin/pla
    if rem_empty:
        rem_idx = []
        for l, sessions in enumerate(linpla_sess):
            if len(sessions) == 0:
                rem_idx.append(l)
        linpla_order = gen_util.remove_idx(linpla_order, rem_idx)
        linpla_sess = gen_util.remove_idx(linpla_sess, rem_idx)

    return linpla_sess, linpla_order


#############################################
def comp_vals_acr_planes(linpla_ord, vals, n_perms=None, normal=True, 
                         stats='mean'):
    """
    comp_vals_acr_planes(linpla_ord, vals)

    Returns p values for comparisons across planes within lines.

    Required args:
        - linpla_ord (list): ordered list of planes/lines
        - vals (list)      : values, structured as 
                             planes/lines x session 

    Optional args:
        - n_perms (int): number of permutations to do if doing a permutation 
                         test. If None, a different test is used
                         default: None
        - stats (str)  : stats to use for permutation test
                         default: 'mean'
        - normal (bool): whether data is expected to be normal or not 
                         (determines whether a t-test or Mann Whitney test 
                         will be done. Ignored if n_perms is not None.)
                         default: True

    Returns:
        - p_vals (2D array): p values, structured as 
                             planes/lines x session
    """

    lines = ['L2/3', 'L5']
    n_sess = len(vals[0])
    p_vals = np.full([len(lines), n_sess], np.nan)
    for li, line in enumerate(lines):
        idx = [i for i in range(len(linpla_ord)) if line in linpla_ord[i]]
        # do comparison
        if len(idx) == 2:
            for s in range(n_sess):
                # check for nans or None
                data = [vals[i][s] for i in idx]
                
                skip = False
                for d in data:
                    if d is None or len(d) == 0:
                        skip = True
                if skip:
                    continue
                                
                if n_perms is not None:                    
                    p_vals[li, s] = math_util.get_diff_p_val(
                        data, n_perms, stats=stats, op='diff')
                elif normal:
                    p_vals[li, s] = scist.ttest_ind(
                        data[0], data[1], axis=None)[1]
                else:
                    p_vals[li, s] = scist.mannwhitneyu(data[0], data[1])[1]

    return p_vals
    

#############################################
def get_n_comps(all_p_vals, n_sess, lin_p_vals=None):
    """
    get_n_comps(all_p_vals, n_sess)

    Returns number of comparisons done for all lines and planes, as well
    as the theoretical max number of comparisons each dataset is included in.

    Required args:
        - all_p_vals (list): list of p-values, structured as 
                             line/plane x comparison
        - n_sess (int)     : number of sessions in each line/plane (incl. None)

    Optional args:
        - lin_p_vals (list): list of p-values, structured as 
                             line x comparison

    Returns:
        - tot_n_comps (int)  : total number of comparisons for all lines and 
                               planes
        - max_comps_per (int): maximum number of comparisons for each dataset 
                               (theoretical - based on number of sessions)
    """

    theor_tot = np.sum(range(n_sess)[1:])
    if theor_tot != len(all_p_vals[0]):
        raise ValueError('Theoretical number of comparisons within '
            f'layer/planes is expected to be {theor_tot}, but is '
            f'{len(all_p_vals[0])}.')

    p_vals = [p for all_ps in all_p_vals for p in all_ps] 
    
    if lin_p_vals is not None:
        p_vals = p_vals + [p for all_ps in lin_p_vals for p in all_ps]

    tot_n_comps = np.count_nonzero(~np.isnan(p_vals))

    # max number of comparisons each dataset is involved in
    max_comps_per = n_sess - 1 + (lin_p_vals is not None)

    return tot_n_comps, max_comps_per
    

#############################################
def data_from_segs(sess, segs, analyspar, stimpar, datatype='roi', 
                   integ=False, baseline=0.1, base_pre=None, ch_fl=None):
    """
    data_from_segs(sess, segs, analyspar, stimpar)

    Returns data for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.1
        - base_pre (num)        : pre value based on which to calculate 
                                  baseline. If None, stimpar.pre is used.
                                  default: None
        - ch_fl (list)          : flanks in sec [pre sec, post sec] around 
                                  frames to check for removal if out of bounds

    Returns:
        - data_arr (1-3D array): data array structured as 
                                 [x ROIs] x seq [x frames]
    """

    stim = sess.get_stim(stimpar.stimtype)

    if analyspar.remnans:
        nanpol = None
    else:
        nanpol = 'omit'

    # get regular, then surprise
    args = {'remnans': analyspar.remnans,
            'scale'  : analyspar.scale}

    if baseline:
        if ch_fl is None:
            ch_fl = [0, 0]
        if base_pre is None:
            base_pre = stimpar.pre
        base_pre, base_post = quint_analys.define_transition_baseline(
            stimpar.stimtype, stimpar.gabfr, baseline, base_pre, stimpar.post)
        # expand flank checking as needed
        ch_fl = [np.max([p, b]) 
            for p, b in zip(ch_fl, [base_pre, base_post])]
    if datatype == 'roi':
        fr_ns = stim.get_twop_fr_by_seg(
            segs, first=True, ch_fl=ch_fl)['first_twop_fr']
        fct = stim.get_roi_data
        col = 'roi_traces'
        args['fluor'] = analyspar.fluor
    elif datatype == 'run':
        # array: 1 x sequences
        fr_ns = stim.get_stim_fr_by_seg(
            segs, first=True, ch_fl=ch_fl)['first_stim_fr']
        fct = stim.get_run_data
        col = 'run_velocity'
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    data_arr = gen_util.reshape_df_data(
        fct(fr_ns, stimpar.pre, stimpar.post, **args)[col], squeeze_cols=True)
    
    if baseline:
        base_data = gen_util.reshape_df_data(
            fct(fr_ns, base_pre, base_post, **args), squeeze_cols=True)
        end_shape = list(base_data.shape)[:-1] + [1]
        # (ROI x) sequences x frames
        base_data = math_util.mean_med(
            base_data, stats=analyspar.stats, axis=-1, nanpol=nanpol)
        data_arr = data_arr - base_data.reshape(end_shape)
    if integ:
        data_arr = math_util.integ(
            data_arr, 1./sess.twop_fps, axis=-1, nanpol=nanpol)
    
    return data_arr


#############################################
def surp_data_by_sess(sess, analyspar, stimpar, datatype='roi', surp='bysurp', 
                      integ=False, baseline=0.1, prog_pos=0):
    """
    surp_data_by_sess(sess, analyspar, stimpar)

    Returns regular and surprise data for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': surp, vs preceeding reg, or
                                  'reglock': reg, vs preceeding surp
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'bysurp'
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.1
        - prog_pos (int)        : surprise or regular position to retrieve if 
                                  surp is 'progsurp' or 'progreg'
                                  default: 0

    Returns:
        - data_arr (list): list of data arrays structured as 
                           reg, surp [x ROIs] x seq [x frames]
                           (or surp, reg if surp in ['reglock', 'progreg'])
    """

    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('stimpar.pre must equal stimpar.post for '
            'this locked analysis.')
    locks = ['reglock', 'surplock'] # ordered in surp == [0, 1] order
    progs = ['progreg', 'progsurp'] # ordered in surp == [0, 1] order

    stim = sess.get_stim(stimpar.stimtype)
    if surp == 'bysurp':
        if stimpar.stimtype == 'gabors' and stimpar.gabfr * 0.3 + stimpar.post < 0.9:
            raise ValueError('Surprise period will not necessarily include '
                f'surprise, with {stimpar.post}s after gaborframe '
                f'{stimpar.gabfr}.')
        segs = [stim.get_segs_by_criteria(
            gabfr=stimpar.gabfr, gabk=stimpar.gabk, gab_ori=stimpar.gab_ori,
            bri_dir=stimpar.bri_dir, bri_size=stimpar.bri_size, surp=s, 
            by='seg') for s in [0, 1]]
        pre_posts = [[stimpar.pre, stimpar.post]] * 2        
    else:
        if surp in locks:
            surp_val = locks.index(surp)
            remconsec = True
            gabfr = 'any'
        elif surp in progs:
            surp_val = progs.index(surp)
            remconsec = False
            gabfr = stimpar.gabfr
        else:
            gen_util.accepted_values_error(
                'surp', surp, 
                ['bysurp', 'surplock', 'reglock', 'progsurp', 'progreg'])

        segs = stim.get_segs_by_criteria(gabfr=gabfr, gabk=stimpar.gabk, 
            gab_ori=stimpar.gab_ori, bri_dir=stimpar.bri_dir, 
            bri_size=stimpar.bri_size, surp=surp_val, by='seg', 
            remconsec=remconsec)
        
        if surp in locks:
            # shift to correct gabor frame
            if (stimpar.stimtype == 'gabors' and 
                stimpar.gabfr not in ['any', 'all']):
                segs = [seg + stimpar.gabfr for seg in segs]
            segs = [segs] * 2
            pre_posts = [[stimpar.pre, 0], [0, stimpar.post]]
        elif surp in progs:
            if not int(prog_pos) == float(prog_pos):
                raise ValueError('prog_pos must be of type int.')
            prog_pos = int(prog_pos)
            # get the shift values for the main and previous segments
            base_shift = 1
            if stimpar.stimtype == 'gabors':
                if gabfr in ['any', 'all']:
                    raise NotImplementedError('Setting `stimpar.gabfr` to '
                        '`any` or `all` has not been sufficiently tested for '
                        '`prog` surp values.')
                base_shift = 4
            main_shift_val = base_shift * prog_pos
            prev_shift_val = base_shift * (1 + prog_pos)

            # get the main segment numbers            
            first_segs, n_consec = gen_util.consec(segs, smallest=True)
            if prog_pos == 0:
                main_segs = first_segs
            else:
                keep_segs_idx = np.where(np.asarray(n_consec) > prog_pos)[0]
                main_segs = np.asarray(first_segs)[keep_segs_idx] + \
                    main_shift_val

            main_segs = list(filter(lambda i : i >= prev_shift_val, main_segs))

            if len(main_segs) == 0:
                raise ValueError('No segments meet the criteria for '
                    f'`prog_pos` = {prog_pos}.')
            
            # [prev_segs, main_segs]
            segs = [[seg - prev_shift_val for seg in main_segs], main_segs]
            pre_posts = [[stimpar.pre, stimpar.post]] * 2   
    
    data_arr = []
    for s, (subsegs, [pre, post]) in enumerate(zip(segs, pre_posts)):
        ch_fl = None
        base_pre = None
        # check flanks and baseline pre adjusted as pre and post are split up!
        if surp in locks:  
            base_pre = stimpar.pre          
            ch_fl = [stimpar.pre, stimpar.post]
        elif surp in progs:
            base_pre = stimpar.pre
            add = prev_shift_val * stim.seg_len_s
            if stimpar.stimtype == 'gabors':
                add += prev_shift_val//4 * stim.seg_len_s
            ch_fl = [stimpar.pre  + (add * (s == 1)), 
                stimpar.post + (add * (s == 0))]

        stimpar_use = sess_ntuple_util.get_modif_ntuple(
            stimpar, ['pre', 'post'], [pre, post])

        data_arr.append(data_from_segs(
            sess, subsegs, analyspar, stimpar_use, datatype, integ=integ, 
            baseline=baseline, base_pre=base_pre, ch_fl=ch_fl))

    return data_arr


#############################################
def dir_data_by_sess(sess, analyspar, stimpar, datatype='roi', integ=False, 
                     baseline=0.1, surp='any', remconsec=False):
    """
    dir_data_by_sess(sess, analyspar, stimpar)

    Returns regular and surprise data for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.1
        - surp (str or int)     : surprise value, e.g. 'any', 0, 1
                                  default: 'any'
        - remconsec (bool)      : if True, consecutive segments are removed
                                  default: False

    Returns:
        - data_arr (list): list of data arrays structured as 
                           left, right [x ROIs] x seq [x frames]
    """


    if stimpar.stimtype != 'bricks':
        raise ValueError('Cannot get direction data for Gabors.')

    if not remconsec and not (baseline is None or baseline == 0):
        raise ValueError('Baseline not implemented for Bricks direction ' 
            'without `remconsec`.')

    stim = sess.get_stim(stimpar.stimtype)
    data_arr = []
    for direc in ['left', 'right']:
        stimpar_sp = sess_ntuple_util.get_modif_ntuple(
            stimpar, 'bri_dir', direc)
        segs = stim.get_segs_by_criteria(
            gabfr=stimpar_sp.gabfr, gabk=stimpar_sp.gabk, 
            gab_ori=stimpar_sp.gab_ori, bri_dir=stimpar_sp.bri_dir, 
            bri_size=stimpar_sp.bri_size, remconsec=remconsec, surp=surp, 
            by='seg')
        data_arr.append(data_from_segs(
            sess, segs, analyspar, stimpar, datatype, integ=integ, 
            baseline=baseline, base_pre=stimpar.pre))

    return data_arr


#############################################
def surp_diff_by_sess(sess, analyspar, stimpar, n_perms=1000, datatype='roi', 
                      surp='bysurp', baseline=0.1):
    """
    surp_diff_by_sess(sess, analyspar, stimpar)
    
    Returns session statistics for difference between surprise and regular
    sequences as well as random values obtained from permutations.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': surp, vs preceeding reg, or
                                  'reglock': reg, vs preceeding surp
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1

    Returns:
        - diff_st (1D array) : session statistics for difference between 
                               surp and regular sequence areas (or vice versa 
                               for surp == 'reglock') (me, err)
        - all_rand (1D array): random value obtained for each permutation
        - data_arr (list)    : list of data arrays, structured as 
                               reg, surp [x ROIs] x seq
                               (or surp, reg if surp in ['reglock', 'progreg'])
    """

    nanpol = 'omit'
    if analyspar.remnans:
        nanpol = None

    data_arr = surp_data_by_sess(sess, analyspar, stimpar, datatype=datatype, 
        surp=surp, integ=True, baseline=baseline)

    # take mean/median across sequences
    mean_meds = [math_util.mean_med(data, stats=analyspar.stats, axis=-1, 
        nanpol=nanpol) for data in data_arr]

    last_dim = np.sum([sub.shape[-1] for sub in data_arr])
    if datatype != 'roi':
        mean_meds = np.asarray(mean_meds).reshape(2, 1)
        targ = (1, last_dim)
    else:
        targ = (-1, last_dim)
    
    diff_st = math_util.get_stats(mean_meds[1] - mean_meds[0], 
        stats=analyspar.stats, error=analyspar.error, nanpol=nanpol)

    # get CI
    div = data_arr[0].shape[-1] # length of reg
    # perms
    all_rand = math_util.mean_med(math_util.permute_diff_ratio(
        np.concatenate(data_arr, axis=-1).reshape(targ), div=div, 
        n_perms=n_perms, stats=analyspar.stats, nanpol=nanpol, op='diff'), 
        stats=analyspar.stats, axis=0, nanpol=nanpol)

    return diff_st, all_rand, data_arr


#############################################
def prog_by_sess(sess, analyspar, stimpar, datatype='roi', surp='progsurp', 
                 position=0, baseline=0):
    """
    prog_by_sess(sess, analyspar, stimpar)
    
    Returns differences between surprises and previous regular 
    sequence across a session, as well as the average for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., prog E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'progsurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1

    Returns:
        - data_arr (2 or 3D array): array of data for surprise and the 
                                    preceeding regular sequence  
                                    (reg, surp), or v.v. if surp is 
                                    'progreg', structured as 
                                    (reg, surp) [x ROIs] x seq
    """

    if surp not in ['progsurp', 'progreg']:
        gen_util.accepted_values_error('surp', surp, ['progsurp', 'regsurp'])

    data_arr = surp_data_by_sess(sess, analyspar, stimpar, datatype=datatype, 
        surp=surp, integ=True, baseline=baseline, 
        prog_pos=position)

    data_arr = np.asarray(data_arr)

    return data_arr


#############################################
def stim_idx_by_sess(sess, analyspar, stimpar, n_perms=1000, datatype='roi', 
                     feature='bysurp', position=0, op='diff'):
    """
    stim_idx_by_sess(sess, analyspar, stimpar)
    
    Returns session item (ROIs or 1 for running) indices for difference between 
    surprise and regular sequences, as well as their percentiles based on 
    random permutations for each item.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - feature (str)         : how to split stimuli, e.g.,
                                  'bysurp': all reg vs all surp, or
                                  'progsurp': first surp, vs preceeding reg, or
                                  'progreg': first reg, vs preceeding surp, or
                                  'dir': left v right direction
                                  default: 'bysurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - op (str)              : operation to use in measuring surprise 
                                  indices ('diff', 'rel_diff', 'discr')
                                  default: 'diff'

    Returns:
        - item_idxs (1D array) : item (ROIs or 1 for running) surprise indices 
                                 for the session
        - item_percs (1D array): item (ROIs or 1 for running) surprise index 
                                 percentiles for the session, based on 
                                 each item's random permutations
        - all_rand (2D array)  : item (ROIs or 1 for running) indices 
                                 calculated through randomized permutation, 
                                    structured as item x n_perms
    """

    nanpol = 'omit'
    if analyspar.remnans:
        nanpol = None

    if 'dir' in feature:
        if feature == 'dir_reg':
            surp = 0
        elif feature == 'dir_surp':
            surp = 1
        elif feature == 'dir':
            surp = 'any'
        else:
            raise ValueError('If `dir` in `feature`, must be '
                'among `dir_reg`, `dir_surp` or `dir`.')

        data_arr = dir_data_by_sess(sess, analyspar, stimpar, 
            datatype=datatype, integ=True, baseline=0, surp=surp, 
            remconsec=False)
    else:
        data_arr = surp_data_by_sess(sess, analyspar, stimpar, 
            datatype=datatype, surp=feature, integ=True, baseline=0, 
            prog_pos=position)
    
    # take statistic across sequences
    seq_mes = np.stack([math_util.mean_med(
        arr, stats=analyspar.stats, axis=-1, nanpol=nanpol) 
        for arr in data_arr])
    
    use_op = op if op != 'discr' else 'diff'

    # take relative difference (index)
    item_idxs = math_util.calc_op(seq_mes, op=use_op, nanpol=nanpol)

    if op == 'discr':
        seq_stds = np.sum([math_util.error_stat(
            arr, stats='mean', error='std', axis=-1, nanpol=nanpol) 
            for arr in data_arr], axis=0)
        item_idxs = 2 * item_idxs / seq_stds

    last_dim = np.sum([sub.shape[-1] for sub in data_arr])
    if datatype != 'roi':
        item_idxs = np.asarray(item_idxs).reshape(-1)
        seq_mes = np.asarray(seq_mes).reshape(2, 1)
        targ = (1, last_dim)
    else:
        targ = (-1, last_dim)

    # get CI
    div = data_arr[0].shape[-1] # length of reg
    # perms (items x perms)
    all_rand = math_util.permute_diff_ratio(
        np.concatenate(data_arr, axis=-1).reshape(targ), div=div, 
        n_perms=n_perms, stats=analyspar.stats, nanpol=nanpol, op=op)

    item_percs = np.empty(len(item_idxs))
    for r, (item_idx, item_rand) in enumerate(zip(item_idxs, all_rand)):
        item_percs[r] = scist.percentileofscore(
            item_rand, item_idx, kind='mean')
    
    return item_idxs, item_percs, all_rand


#############################################
def stim_idx_by_sesses(sessions, analyspar, stimpar, n_perms=1000, p_val=0.05, 
                       datatype='roi', feature='bysurp', position=0, seed=None,
                       parallel=False):
    """
    stim_idx_by_sesses(sessions, analyspar, stimpar)
    
    Returns item (ROIs or running) indices for difference between 
    stimulus features (e.g., surprise v regular, brick direction), as well as 
    their percentiles based on random permutations for each item, grouped 
    across mice for each session number.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - p_val (float)         : p-value (used to decide number of bins)
                                  default: 0.05
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - feature (str)         : how to split stimuli, e.g.,
                                  'bysurp': all reg vs all surp, or
                                  'progsurp': first surp, vs preceeding reg, or
                                  'progreg': first reg, vs preceeding surp, or
                                  'dir_reg': left v right direction (regular),
                                  'dir_surp': left v right direction (surprise),
                                  'dir': left v right direction
                                  default: 'bysurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0 
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, sessions are analysed in parallel
                                  default: False
    Returns:
        - all_item_idxs (list) : for each session number, item (ROIs or running) 
                                 surprise index bin counts grouped across mice
        - all_item_percs (list): for each session number, item (ROIs or running) 
                                 surprise index percentile bin counts, based on 
                                 each item's random permutations, grouped 
                                 across mice
        - all_rand_idxs (list) : for each session number, binned random item 
                                 (ROIs or running) surprise index bin counts, 
                                 based on each item's random permutations, 
                                 grouped across mice, structured as 
                                    session x (item * n_perms)
        - sess_edges (list)    : for each session number, bin edges used for 
                                 indices, 
                                    session x [min, max]
        - sess_info (list)     : nested list of dictionaries for each 
                                 session number containing information from each 
                                 mouse, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    op = 'discr'

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    seed = gen_util.seed_all(seed, 'cpu', print_seed=False)

    n_mice = len(sessions)
    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
            'each mouse.')
    n_sess = n_sess[0]

    n_bins = 4/p_val
    if n_bins != int(n_bins):
        raise NotImplementedError(f'Analysis not well adapted to binning '
            f'with p-value of {p_val}.')
    else:
        n_bins = int(n_bins)

    all_item_idxs, all_item_percs, all_rand_idxs = [], [], []
    sess_edges = []
    sess_info = []
    for s in range(n_sess):
        sesses = []
        all_items, all_percs, all_rand = [], [], []
        for m in range(n_mice):
            sess = sessions[m][s]
            sesses.append(sess)
            if sess is None:
                continue
            try:
                item_idxs, item_percs, rand_idxs = stim_idx_by_sess(
                    sess, analyspar, stimpar, n_perms, datatype, feature, 
                    position, op)
            except Exception as e:
                if 'dir' in feature and 'No segments' in str(e):
                    continue
                else:
                    raise e
            all_items.extend(item_idxs.tolist())
            all_percs.extend(item_percs.tolist())
            all_rand.extend(rand_idxs.tolist())
            
        sess_info.append(sess_gen_util.get_sess_info(
            sesses, analyspar.fluor, add_none=True, incl_roi=(datatype=='roi')))
        
        if len(all_rand) == 0:
            use_bounds = [-0.5, 0.5]
            bin_edges = np.linspace(*use_bounds, n_bins + 1)
            all_item_idxs.append(
                np.histogram(all_items, bins=bin_edges)[0].tolist())
            all_rand_idxs.append(
                (np.histogram(all_rand, bins=bin_edges)[0]).tolist())
            sess_edges.append([np.min(bin_edges), np.max(bin_edges)])
            all_item_percs.append(
                np.histogram(
                    all_percs, bins=n_bins, range=[0, 100])[0].tolist())
            continue
        
        # get edges for histogram 
        all_rand = np.concatenate(all_rand, axis=0)
        div = len(all_rand)/float(len(all_items))

        if op in ['diff', 'discr']:
            use_bounds = [np.min(all_rand), np.max(all_rand)]
        elif op == 'rel_diff':
            # use extrema or outlier bounds, whichever are tighter
            rand_outlier_bounds = math_util.outlier_bounds(
                all_rand, fences='outer')
            use_bounds = [fct([o, fct(all_rand)]) for o, fct in 
                zip(rand_outlier_bounds, [np.max, np.min])]
                
        # ensure that real data is fully included
        use_bounds = [fct([fct(all_items), r]) 
            for r, fct in zip(use_bounds, [np.min, np.max])]

        n_out = np.sum(all_rand < use_bounds[0]) + \
            np.sum(all_rand > use_bounds[1])
        if n_out > 0:
            print(f'    Warning: {n_out}/{len(all_rand)} random values lie '
                'outside histogram bin bounds (outliers).')

        bin_edges = np.linspace(*use_bounds, n_bins + 1)
        
        all_item_idxs.append(
            np.histogram(all_items, bins=bin_edges)[0].tolist())
        all_rand_idxs.append(
            (np.histogram(all_rand, bins=bin_edges)[0]/div).tolist())
        sess_edges.append([np.min(bin_edges), np.max(bin_edges)])

        all_item_percs.append(
            np.histogram(all_percs, bins=n_bins, range=[0, 100])[0].tolist())

    return [all_item_idxs, all_item_percs, all_rand_idxs, sess_edges, 
        sess_info]


#############################################
def get_grped_roi_stats(all_roi_vals, analyspar, permpar):
    """
    get_grped_roi_stats(all_roi_vals, analyspar, permpar)

    Returns difference between surprise and regular sequence information with
    ROIs grouped across mice.

    Required args:
        - all_roi_vals (list)  : session values for surprise and regular  
                                 sequence areas (or vice versa 
                                 for surp == 'reglock') for each ROI, structured
                                 as session x surps x ROI x seqs
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  

    Returns:
        - all_diff_st (list) : difference stats across ROIs (grouped across 
                               mice), structured as session x stats
        - CI_vals (list)     : CIs values across ROIs, structured as 
                               session x perc (med, lo, high)
        - sign_sess (list)   : significant session indices, optionally 
                               structured by tail
        - all_diffs (list)   : differences, structured as session x ROI
        - p_vals_grped (list): p values for each comparison, organized by 
                               session pairs (where the second session is cycled 
                               in the inner loop, e.g., 0-1, 0-2, 1-2, including 
                               empty groups)
    """

    # join ROIs across mice
    percs = [50.0] + math_util.get_percentiles(CI = (1.0 - permpar.p_val))[0]
    st_len = 2 + (analyspar.stats == 'median' and analyspar.error == 'std')

    nanpol = 'omit'
    if analyspar.remnans:
        nanpol = None

    n_sess = len(all_roi_vals)
    all_diff_st = np.empty([n_sess, st_len]) * np.nan
    all_rand = np.empty([n_sess, permpar.n_perms]) * np.nan
    all_diffs = []
    for s, sess_roi_vals in enumerate(all_roi_vals):
        # mice x (reg, surp) x ROIs x seqs
        sess_mean_meds = []
        sess_rands = []
        for mouse_vals in sess_roi_vals: # for each mouse
            sess_mean_meds.append([math_util.mean_med(surp_vals, axis=-1, 
                stats=analyspar.stats) for surp_vals in mouse_vals])
            # get CI
            div = mouse_vals[0].shape[-1] # length of reg
            # perms
            sess_rands.append(math_util.permute_diff_ratio(
                np.concatenate(mouse_vals, axis=1), div=div, 
                n_perms=permpar.n_perms, stats=analyspar.stats, 
                nanpol=nanpol, op='diff'))

        if len(sess_mean_meds) == 0:
            all_diffs.append(None)
            continue

        # take mean/median across sequences, then diff between surp and reg
        sess_mean_med_diffs = np.subtract(
            *np.concatenate(sess_mean_meds, axis=1)) * -1
        # take stats across ROIs
        all_diff_st[s] = math_util.get_stats(sess_mean_med_diffs, 
            stats=analyspar.stats, error=analyspar.error, nanpol=nanpol)
        # sess_rands: mouse x ROI x perm
        all_rand[s] = math_util.mean_med(
            np.concatenate(sess_rands, axis=0), axis=0, stats=analyspar.stats)
        all_diffs.append(sess_mean_med_diffs.tolist())

    # get p-values for comparisons between sessions
    p_vals_grped = math_util.comp_vals_acr_groups(all_diffs, permpar.n_perms, 
        stats=analyspar.stats).tolist()
    
    # get CI (sess x percs)
    CI_vals = np.asarray(
        [np.percentile(all_rand, p, axis=-1) for p in percs]).T.tolist()

    # get significant session numbers (optionally by tails)
    sign_sess = math_util.id_elem(all_rand, all_diff_st[:, 0], 
        tails=permpar.tails, p_val=permpar.p_val, min_n=25, nanpol='omit')

    return all_diff_st.tolist(), CI_vals, sign_sess, all_diffs, p_vals_grped


#############################################
def get_mouse_stats(mouse_diff_st, all_rand, analyspar, permpar):
    """
    get_mouse_stats(mouse_diff_st, all_rand, analyspar, permpar)

    Returns difference between surprise and regular sequence information across 
    mice.

    Required args:
        - mouse_diff_st (3D array): difference statistics across ROIs or seqs, 
                                    structured as mouse x session x stats
        - all_rand (1D array)     : random values obtained for each permutation, 
                                    structured as mouse x session x perm
        - analyspar (AnalysPar)   : named tuple containing analysis parameters
        - permpar (PermPar)       : named tuple containing permutation 
                                    parameters  

    Returns:
        - all_diff_st (list): difference stats across mice, structured as 
                              session x stats
        - CI_vals (list)    : CIs values, structured as 
                              session x perc (med, lo, high)
        - sign_sess (list)  : significant session indices, optionally 
                              structured by tail
    """

    # take stats across mice
    percs = [50.0] + math_util.get_percentiles(CI = (1.0 - permpar.p_val))[0]

    # sess x stats
    all_diff_st = math_util.get_stats(mouse_diff_st[:, :, 0], 
        stats=analyspar.stats, error=analyspar.error, axes=0, nanpol='omit').T

    # take mean/median across mice (sess x perms)
    all_rand = math_util.mean_med(
        all_rand, stats=analyspar.stats, axis=0, nanpol='omit')
    
    # get CI (sess x percs)
    CI_vals = np.asarray(
        [np.percentile(all_rand, p, axis=-1) for p in percs]).T.tolist()

    # get significant session numbers (optionally by tails)
    sign_sess = math_util.id_elem(
        all_rand, all_diff_st[:, 0], tails=permpar.tails, p_val=permpar.p_val, 
        min_n=25, nanpol='omit')
    
    return all_diff_st.tolist(), CI_vals, sign_sess


#############################################
def surp_diff_by_sesses(sessions, analyspar, stimpar, permpar, datatype='roi', 
                        surp='bysurp', baseline=0.1, seed=None):
    """
    surp_diff_by_sesses(sessions, analyspar, stimpar, permpar)

    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp'  : all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg
                                  'reglock' : first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None

    Returns:
        - mouse_diff_st (list)   : difference statistics across ROIs or seqs, 
                                   structured as mouse x session x stats
        - all_diff_st (list)     : difference stats across mice, 
                                   structured as session x stats
        - CI_vals (list)         : CIs values, structured as 
                                   session x perc (med, lo, high)
        - sign_sess (list)       : significant session indices, optionally
                                   structured by tail
        if datatype == 'roi':
            - all_diff_st_grped (list) : difference stats across ROIs (grouped 
                                         across mice), structured as 
                                         session x stats
            - CI_vals_grped (list)     : CIs values across ROIs, structured as 
                                         session x perc (med, lo, high)
            - sign_sess_grped (list)   : significant session indices, 
                                         optionally structured by tail
            - all_diffs   (list)       : differences, structured as 
                                         session x ROI
            - p_vals_grped (list)      : p values for each comparison, 
                                         organized by session pairs (where the 
                                         second session is cycled in the inner 
                                         loop, e.g., 0-1, 0-2, 1-2, including 
                                         empty groups)

        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
            'each mouse.')
    n_sess = n_sess[0]

    st_len = 2 + (analyspar.stats == 'median' and analyspar.error == 'std')

    seed = gen_util.seed_all(seed, 'cpu', print_seed=False)

    n_mice = len(sessions)
    mouse_diff_st = np.empty([n_mice, n_sess, st_len]) * np.nan
    all_rand = np.empty([n_mice, n_sess, permpar.n_perms]) * np.nan
    all_roi_vals = [[] for _ in range(n_sess)]
    sess_info = []
    for m, m_sess in enumerate(sessions):
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(
            m_sess, analyspar.fluor, add_none=True, incl_roi=(datatype=='roi'))
        for s, sess in enumerate(m_sess):
            if sess is None:
                continue
            mouse_diff_st[m, s], all_rand[m, s], add_rois = surp_diff_by_sess(
                sess, analyspar, stimpar, n_perms=permpar.n_perms, 
                datatype=datatype, surp=surp, baseline=baseline)
            if datatype == 'roi':
                all_roi_vals[s].append(add_rois)

        sess_info.append(m_sess_info)

    [all_diff_st, CI_vals, sign_sess] = get_mouse_stats(
        mouse_diff_st, all_rand, analyspar, permpar)
    
    if datatype == 'roi':
        [all_diff_st_grped, CI_vals_grped, sign_sess_grped, 
            all_diffs_grped, p_vals_grped] = get_grped_roi_stats(
                all_roi_vals, analyspar, permpar)    
    

        return [mouse_diff_st.tolist(), all_diff_st, CI_vals, sign_sess, 
            all_diff_st_grped, CI_vals_grped, sign_sess_grped, 
            all_diffs_grped, p_vals_grped, sess_info]

    elif datatype == 'run':
        return [mouse_diff_st.tolist(), all_diff_st, CI_vals, sign_sess, 
            sess_info]
    

#############################################
def surp_diff_by_linpla(sessions, analyspar, stimpar, permpar, datatype='roi', 
                        surp='bysurp', baseline=0.1, seed=None, parallel=False):
    """
    surp_diff_by_linpla(sessions, analyspar, stimpar, permpar)
    
    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)         : type of data (e.g., 'roi', 'run')
                                   default: 'roi'
        - surp (str)             : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp, or                           
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1        
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - diff_info (dict)       : dictionary with difference info
            ['all_diff_stats'] (list)  : difference stats across mice, 
                                         structured as plane/line x session 
                                                                  x stats
            ['mouse_diff_stats'] (list): difference statistics across ROIs or 
                                         seqs, structured as 
                                             plane/line x mouse x session 
                                                        x stats
            ['CI_vals'] (list)         : CIs values, structured as
                                             plane/line x session 
                                                        x perc (med, lo, high)
            ['sign_sess'] (list)       : significant session indices, 
                                         structured as plane/line (x tails)
            ['linpla_ord'] (list)      : order list of planes/lines
        if datatype == 'roi':
            ['all_diff_st_grped'] (list): difference stats across ROIs (grouped 
                                          across mice), structured as 
                                          plane/line x session x stats
            ['CI_vals_grped'] (list)    : CIs values across ROIs, structured as 
                                          plane/line x session 
                                                     x perc (med, lo, high)
            ['lin_p_vals'] (list)       : p-values for each line comparison, 
                                          structured as line x session (np.nan 
                                          for sessions  missing in either plane)
            ['max_comps_per'] (int)     : total number of comparisons
            ['p_vals_grped'] (list)     : p values for each comparison, 
                                          organized by session pairs (where the 
                                          second session is cycled in the inner 
                                          loop, e.g., 0-1, 0-2, 1-2, including 
                                          empty groups)
            ['sign_sess_grped'] (list)  : significant session indices, 
                                          structured as plane/line (x tails)
            ['tot_n_comps'] (int)       : total number of comparisons

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if permpar.multcomp:
        raise ValueError('Multiple comparisons not implemented for this '
            'analysis.')
    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('For surplock or reglock analysis, stimpar.pre and '
            'stimpar.post must be the same.')
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
    if parallel:
        outs = Parallel(n_jobs=n_jobs)(delayed(surp_diff_by_sesses)(
            sessions, analyspar, stimpar, permpar, datatype, surp, baseline, 
            seed) for sessions in linpla_sess)
    else:
        outs = []
        for sessions in linpla_sess:
            outs.append(surp_diff_by_sesses(sessions, analyspar, stimpar, 
                permpar, datatype, surp, baseline, seed))
    outs = [list(out) for out in zip(*outs)]

    diff_info = dict()
    if datatype == 'roi':
        [mouse_diff_st, all_diff_st, all_CI_vals, all_sign_sess, 
            all_diff_st_grped, all_CI_vals_grped, all_sign_sess_grped, 
            all_diffs_grped, all_p_vals_grped, sess_info] = outs
        diff_info['all_diff_stats_grped'] = all_diff_st_grped
        diff_info['CI_vals_grped']    = all_CI_vals_grped
        diff_info['sign_sess_grped']  = all_sign_sess_grped
        diff_info['p_vals_grped']     = all_p_vals_grped
        
        # compare across planes in a line
        lin_p_vals = comp_vals_acr_planes(linpla_order, all_diffs_grped, 
            permpar.n_perms, stats=analyspar.stats)
        n_sess = len(all_diffs_grped[0])
        tot_n_comps, max_comps_per = get_n_comps(
            all_p_vals_grped, n_sess, lin_p_vals)
        diff_info['lin_p_vals']    = lin_p_vals.tolist()
        diff_info['tot_n_comps']   = tot_n_comps
        diff_info['max_comps_per'] = max_comps_per

    elif datatype == 'run':
        [mouse_diff_st, all_diff_st, all_CI_vals, 
         all_sign_sess, sess_info] = outs
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    diff_info['all_diff_stats']   = all_diff_st
    diff_info['mouse_diff_stats'] = mouse_diff_st
    diff_info['CI_vals']          = all_CI_vals
    diff_info['sign_sess']        = all_sign_sess
    diff_info['linpla_ord']       = linpla_order

    return diff_info, sess_info


#############################################
def run_surp_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar, datatype='roi', 
                       parallel=False):
    """
    run_surp_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar)

    Retrieves area values by session x surp val and plots statistics across 
    ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.bri_dir, stimpar.bri_size, stimpar.gabk,
        'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise - regular locked {datastr} '
        f'responses \n({sessstr_pr}{dendstr_pr}).')

    if permpar.multcomp:
        print('NOTE: Multiple comparisons not implemented for this analysis. '
              'Setting to False.')
        permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'multcomp', False)

    diff_info, sess_info = surp_diff_by_linpla(
        sessions, analyspar, stimpar, permpar, datatype, surp='bysurp', 
        baseline=basepar.baseline, seed=seed, parallel=parallel)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                'seed'    : seed,
                }

    info = {'analyspar': analyspar._asdict(),
            'sesspar'  : sesspar._asdict(),
            'stimpar'  : stimpar._asdict(),
            'basepar'  : basepar._asdict(),
            'permpar'  : permpar._asdict(),
            'extrapar' : extrapar,
            'sess_info': sess_info,
            'diff_info': diff_info
            }

    fulldir, savename = acr_sess_plots.plot_surp_area_diff(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')

      
#############################################
def run_lock_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar, datatype='roi', 
                       parallel=False):
    """
    run_lock_area_diff(sessions, analysis, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar)

    Retrieves area values by session x surp val, locked to surprise onset and 
    plots statistics across ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.bri_dir, stimpar.bri_size, stimpar.gabk,
        'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise - regular {datastr} responses '
        f' \n({sessstr_pr}{dendstr_pr}).')

    if permpar.multcomp:
        print('NOTE: Multiple comparisons not implemented for this analysis. '
              'Setting to False.')
        permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'multcomp', False)

    if stimpar.pre != stimpar.post:
        print(f'WARNING: stimpar.post {stimpar.post} will be used for '
              'pre and post.')
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, 'pre', stimpar.post)
    
    all_diff_info = []
    all_sess_info = []
    for lock in ['surplock', 'reglock']:
        diff_info, sess_info = surp_diff_by_linpla(
            sessions, analyspar, stimpar, permpar, datatype, surp=lock, 
            baseline=basepar.baseline, seed=seed, parallel=parallel)
        all_diff_info.append(diff_info)
        all_sess_info.append(sess_info)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                'seed'    : seed,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'permpar'   : permpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'diff_info' : all_diff_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_area_diff(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')
    

#############################################
def surp_traces_by_sesses(sessions, analyspar, stimpar, datatype='roi', 
                          surp='bysurp', baseline=0.1):
    """
    surp_traces_by_sesses(sessions, analyspar, stimpar)

    Returns dictionary containing surprise and regular sequence information, as 
    well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1
    
    Returns:
        - traces_acr_mice (list)  : mean traces across ROIs and sequences, 
                                    structured as
                                      mouse x session x reg/surp x frame
                                      (or surp/reg if surp == 'reglock')
        - sess_info (nested list) : nested list of dictionaries for each 
                                    mouse containing information from each 
                                    session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
        if datatype == 'roi':
        - traces_acr_rois (list)  : mean traces across sequences, structured as
                                      session x mouse x reg/surp [x ROI] x frame
                                      (or surp/reg if surp == 'reglock')

    """

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
            'each mouse.')
    n_sess = n_sess[0]

    sess_info = []
    traces_acr_mice = []
    traces_acr_rois = [[] for _ in range(n_sess)]
    for m_sess in sessions:
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(m_sess, analyspar.fluor, 
            add_none=True, incl_roi=(datatype=='roi'))
        nan_idx = []
        mouse_traces = []
        for s, sess in enumerate(m_sess):
            if sess is None:
                nan_idx.append(s)
                continue
            # reg, surp [x ROI] x seq x frames
            data_arr = surp_data_by_sess(sess, analyspar, stimpar, 
                datatype=datatype, surp=surp, baseline=baseline)
            # get mean/median across seqs
            data_arr = [math_util.mean_med(sub_arr, stats=analyspar.stats, 
                axis=-2) for sub_arr in data_arr]
            if datatype == 'roi': # get mean/median across ROIs
                mean_med = [math_util.mean_med(sub_arr, stats=analyspar.stats, 
                    axis=0) for sub_arr in data_arr]
                traces_acr_rois[s].append(data_arr)
            elif datatype == 'run':
                mean_med = data_arr
            mouse_traces.append(mean_med)
        sess_info.append(m_sess_info)
        mouse_traces = np.asarray(mouse_traces)

        for i in nan_idx: # add NaNs back in for appropriate sessions
            mouse_traces = np.insert(mouse_traces, i, np.nan, axis=0)
        traces_acr_mice.append(mouse_traces)

    if datatype == 'roi':
        return traces_acr_mice, sess_info, traces_acr_rois
    else:
        return traces_acr_mice, sess_info


#############################################
def surp_trace_stats_by_sesses(sessions, analyspar, stimpar, datatype='roi', 
                               surp='bysurp', baseline=0.1):
    """
    surp_trace_stats_by_sesses(sessions, analyspar, stimpar)
    
    Returns dictionary containing surprise and regular sequence information, as 
    well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1

    Returns:       
        - trace_st (list)         : trace statistics, structured as
                                    session x reg/surp x frame x stats
                                    (or surp/reg if surp == 'reglock')
        if datatype == 'roi':
            - trace_st_acr_rois (list): trace statistics across ROIs, grouped 
                                        across mice, structured as
                                        session x reg/surp x frame x stats
                                        (or surp/reg if surp == 'reglock')
        - xran (list)             : second values for each frame
        - sess_info (nested list) : nested list of dictionaries for each 
                                    mouse containing information from each 
                                    session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    returns = surp_traces_by_sesses(
        sessions, analyspar, stimpar, datatype, surp, baseline)
    
    traces_acr_mice = returns[0]
    sess_info = returns[1]

    # stats x sess x reg/surp x frames
    trace_st = math_util.get_stats(np.asarray(traces_acr_mice), 
        stats=analyspar.stats, error=analyspar.error, axes=0, nanpol='omit')
    n_fr = trace_st.shape[-1]
    trace_st = np.transpose(trace_st, [1, 2, 3, 0]).tolist()

    pre = stimpar.pre
    if surp in ['surplock', 'reglock']:
        pre = 0
    xran = np.linspace(-pre, stimpar.post, n_fr).tolist()

    # stats across ROIs (grouped across mice)
    if datatype == 'roi':
        traces_acr_rois = returns[2]
        nan_idx = []
        trace_st_acr_rois = []
        for s, sess_traces in enumerate(traces_acr_rois):
            if len(sess_traces) == 0:
                nan_idx.append(s)
                continue
            # surp/reg x ROIs x frames
            sess_traces = np.concatenate(sess_traces, axis=1)
            # reg/surp x frames x stats
            sess_sts = np.transpose(math_util.get_stats(sess_traces, 
                stats=analyspar.stats, error=analyspar.error, 
                axes=1, nanpol='omit'), [1, 2, 0])
            trace_st_acr_rois.append(sess_sts.tolist())
        for i in nan_idx:
            trace_st_acr_rois = np.insert(trace_st_acr_rois, i, np.nan, 
                axis=0).tolist()

        return trace_st, trace_st_acr_rois, xran, sess_info
    
    else:
        return trace_st, xran, sess_info


#############################################
def surp_traces_by_linpla(sessions, analyspar, stimpar, datatype='roi', 
                          surp='bysurp', baseline=0.1, parallel=False):
    """
    surp_traces_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp'  : all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock' : first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - trace_info (dict)      : dictionary with difference info
            ['linpla_ord'] (list) : order list of planes/lines            
            ['trace_stats'] (list): trace statistics, structured as
                                    plane/line x session x reg/surp x frame 
                                               x stats
                                    (or surp/reg if surp == 'reglock')
            ['xran'] (list)       : second values for each frame
            if datatype == 'roi':
                ['trace_st_grped'] (list): trace statistics across ROIs, 
                                           grouped across mice, structured 
                                           as session x reg/surp 
                                                      x frame x stats
                                           (or surp/reg if surp == 'reglock')

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('For surplock or reglock analysis, stimpar.pre and '
            'stimpar.post must be the same.')

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
    if parallel:
        outs = Parallel(n_jobs=n_jobs)(delayed(surp_trace_stats_by_sesses)(
            sessions, analyspar, stimpar, datatype, surp, baseline)
            for sessions in linpla_sess)
    else:
        outs = []
        for sessions in linpla_sess:
            outs.append(surp_trace_stats_by_sesses(
                sessions, analyspar, stimpar, datatype, surp, baseline))
    outs = [list(out) for out in zip(*outs)]

    if datatype == 'run':
        [trace_stats, xrans, sess_info] = outs    
    elif datatype == 'roi':
        [trace_stats, trace_stats_acr_rois, xrans, sess_info] = outs    
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    trace_info = {'xran'       : xrans[0],
                  'trace_stats': trace_stats,
                  'linpla_ord' : linpla_order
                  }

    if datatype == 'roi':
        trace_info['trace_stats_grped'] = trace_stats_acr_rois

    return trace_info, sess_info


#############################################
def run_surp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar, datatype='roi', parallel=False):
    """
    run_surp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar)

    Retrieves area values by session x surp val and plots statistics across 
    ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise v regular {datastr} traces '
        f' \n({sessstr_pr}{dendstr_pr}).')

    trace_info, sess_info = surp_traces_by_linpla(
        sessions, analyspar, stimpar, datatype, surp='bysurp', 
        baseline=basepar.baseline, parallel=parallel)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : sess_info,
            'trace_info': trace_info
            }

    fulldir, savename = acr_sess_plots.plot_surp_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')

      
#############################################
def run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar, datatype='roi', parallel=False):
    """
    run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar)

    Retrieves area values by session x surp val, locked to surprise, then 
    regular onset and plots statistics across ROIs of difference between 
    regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise v regular locked {datastr} '
        f'traces \n({sessstr_pr}{dendstr_pr}).')

    if stimpar.pre != stimpar.post:
        print(f'WARNING: stimpar.post {stimpar.post} will be used for '
            'pre and post.')
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, 'pre', stimpar.post)

    if stimpar.stimtype == 'gabors':
        n_cycles = stimpar.post/1.5
        if int(n_cycles) != n_cycles:
            raise ValueError('Locked analysis should not be used for '
                'incomplete gabor cycles, as different parts of the cycle '
                'are then compared.')

    all_sess_info = []
    all_trace_info = []
    for lock in ['surplock', 'reglock']:
        trace_info, sess_info = surp_traces_by_linpla(
            sessions, analyspar, stimpar, datatype, surp=lock, 
            baseline=basepar.baseline, parallel=parallel)
        all_sess_info.append(sess_info)
        all_trace_info.append(trace_info)
        

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'trace_info': all_trace_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def prog_by_sesses(sessions, analyspar, stimpar, datatype='roi', 
                   surp='progsurp', position=0, baseline=0.0, seq_st=False, 
                   diff=False):
    """
    prog_by_sesses(sessions, analyspar, stimpar)

    Returns differences between surprise and preceeding regular 
    sequence (or v.v.), as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'progsurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.0
        - seq_st (bool)         : if True, stats are taken across sequences
                                  default: False

    Returns:
        - mouse_seq_st (list)    : difference statistics across ROIs for each 
                                   sequence or across sequences, structured as 
                                       mouse x session [x surps] [x seqs] 
                                           x stats
        - all_seq_st (list)      : difference statistics across mice for each 
                                   sequence, structured as 
                                       session [x surps] [x seqs] x stats
        if datatype == 'roi':
            - grped_seq_st (list): difference statistics across ROIs grouped by 
                                   session for each sequence, or across 
                                   sequences, structured as 
                                       session [x surps] [x seqs] x stats
        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
            'each mouse.')
    n_sess = n_sess[0]

    st_len = 2 + (analyspar.stats == 'median' and analyspar.error == 'std')

    nanpol = 'omit'
    if analyspar.remnans:
        nanpol = None

    n_mice = len(sessions)
    upper_bound = 1000

    # n_mice x n_sess x surp/reg x n_seq x stats
    mouse_seq_st = np.empty([n_mice, n_sess, 2, upper_bound, st_len]) * np.nan
    if diff:
        mouse_seq_st = mouse_seq_st[:, :, 0]

    all_roi_vals = [[] for _ in range(n_sess)]
    sess_info = []
    cut_seq = upper_bound
    for m, m_sess in enumerate(sessions):
        m_sess_info = sess_gen_util.get_sess_info(
            m_sess, analyspar.fluor, add_none=True, incl_roi=(datatype=='roi'))
        for s, sess in enumerate(m_sess):
            if sess is None:
                continue
            # surp (reg, surp or v.v.) x (ROIs x) sequences
            try:
                data_arr = prog_by_sess(sess, analyspar, stimpar, 
                    datatype=datatype, surp=surp, position=position, 
                    baseline=baseline)
                if diff:
                    data_arr = data_arr[1] - data_arr[0]
            except Exception as e:
                # catch error if the position value is too high and no segments 
                # meet the criteria
                if 'No segments' in str(e):
                    continue
                else:
                    raise(e)
            n_seqs = data_arr.shape[-1]
            if n_seqs > mouse_seq_st.shape[-2]:
                raise NotImplementedError('Implementation problem: '
                    f'`upper_bound` set too low at {upper_bound}, as some '
                    f'sessions have {n_seqs} sequences.')
            cut_seq = np.min([cut_seq, n_seqs])
            upper_bound = None # allows a later check

            # set target slice (mouse, session, surp/reg)
            targ_slice = (slice(m, m + 1), slice(s, s + 1), slice(None))
            if diff:
                targ_slice = targ_slice[:-1]
            if datatype == 'roi':
                all_roi_vals[s].append(data_arr)
                mouse_seq_st[targ_slice + (slice(0, n_seqs), )] = \
                    np.moveaxis(math_util.get_stats(
                        data_arr, stats=analyspar.stats, error=analyspar.error, 
                        axes=-2, nanpol=nanpol), 0, -1)
            else:
                mouse_seq_st[targ_slice + (slice(0, n_seqs), 0)] = data_arr
        sess_info.append(m_sess_info)

    # cut down to number of sequences
    mouse_seq_st = mouse_seq_st[..., :cut_seq, :]

    if seq_st:
        mouse_seq_st = np.moveaxis(math_util.get_stats(
            mouse_seq_st[..., 0], stats=analyspar.stats, 
            error=analyspar.error, axes=-1, nanpol='omit'), 0, -1)

    all_seq_st = np.moveaxis(math_util.get_stats(mouse_seq_st[..., 0], 
        stats=analyspar.stats, error=analyspar.error, axes=0, 
        nanpol='omit'), 0, -1).tolist()

    if datatype == 'roi':
        # session x mouse [x surps] x [ROI x seqs] -> 
        # session [x surps] [x seqs] x stats
        grped_seq_st = []
        for sess_vals in all_roi_vals:
            if len(sess_vals) == 0:
                cut_seq = cut_seq if upper_bound is None else 1
                targ_shape = [cut_seq, st_len]
                if seq_st:
                    targ_shape = [st_len]
                if not diff:
                    targ_shape = [2] + targ_shape
                grped_seq_st.append((np.empty(targ_shape) * np.nan).tolist())
            else:
                sess_vals = np.concatenate(
                    [data[..., :cut_seq] for data in sess_vals], axis=-2) 
                targ_ax = -2
                if seq_st:
                    targ_ax = [-2, -1]

                grped_seq_st.append(np.moveaxis(math_util.get_stats(
                    sess_vals, stats=analyspar.stats, error=analyspar.error, 
                    axes=targ_ax, nanpol=nanpol), 0, -1).tolist())

        return mouse_seq_st.tolist(), all_seq_st, grped_seq_st, sess_info

    else:
        return mouse_seq_st.tolist(), all_seq_st, sess_info
        

#############################################
def prog_by_linpla(sessions, analyspar, stimpar, datatype='roi', 
                   surp='progsurp', position=0, baseline=0.0, 
                   parallel=False):
    """
    prog_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing difference between surprise 
    and the preceeding regular sequence (or v.v.), as well as lists of session 
    information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'progsurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - prog_info (dict)       : dictionary with surprise progression info
            ['prog_stats'] (list)           : surprise progression stats across 
                                              mice, structured as 
                                                  plane/line x session x surps 
                                                  x seq x stats
            ['prog_diff_stats'] (list)      : surprise difference progression 
                                              stats across mice, structured as 
                                                  plane/line x session x seq 
                                                  x stats
            ['mouse_prog_stats'] (list)     : surprise progression stats across 
                                              ROIs, structured as 
                                                 plane/line x mouse x session x
                                                 surps x seq x stats
            ['mouse_prog_diff_stats'] (list): surprise difference progression 
                                              stats across ROIs, structured as 
                                                 plane/line x mouse x session x
                                                 seq x stats

            ['linpla_ord'] (list)      : order list of planes/lines
        if datatype == 'roi':
            ['prog_stats_grped'] (list)     : surprise progression stats across 
                                              ROIs (grouped across mice), 
                                              structured as 
                                                  plane/line x session x surps 
                                                  x seqs x stats
            ['prog_diff_stats_grped'] (list): surprise difference progression 
                                              stats across ROIs (grouped across 
                                              mice), structured as 
                                                  plane/line x session 
                                                  x seqs x stats
        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    prog_info = dict()
    for diff in [False, True]:
        n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
        if parallel:
            outs = Parallel(n_jobs=n_jobs)(delayed(prog_by_sesses)(
                sessions, analyspar, stimpar, datatype, surp, position, 
                baseline, diff=diff)
                for sessions in linpla_sess)
        else:
            outs = []
            for sessions in linpla_sess:
                outs.append(prog_by_sesses(sessions, analyspar, stimpar, 
                    datatype, surp, position, baseline, diff=diff))
        outs = [list(out) for out in zip(*outs)]

        diff_str = '_diff' if diff else ''

        if datatype == 'roi':
            [mouse_seq_st, all_seq_st, grped_seq_st, sess_info] = outs
            prog_info[f'prog{diff_str}_stats_grped'] = grped_seq_st
            
        elif datatype == 'run':
            [mouse_seq_st, all_seq_st, sess_info] = outs
        else:
            gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

        prog_info[f'prog{diff_str}_stats']       = all_seq_st
        prog_info[f'mouse_prog{diff_str}_stats'] = mouse_seq_st
        prog_info['linpla_ord']                  = linpla_order

    return prog_info, sess_info


#############################################
def position_by_linpla(sessions, analyspar, stimpar, datatype='roi', 
                       surp='progsurp', position=0, baseline=0.0, 
                       parallel=False):
    """
    position_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing stats for difference between surprise and the 
    preceeding regular sequence (or v.v.), across sessions, as well as 
    session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  default: 'progsurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - pos_info (dict)       : dictionary with surprise position info
            ['pos_stats'] (list)      : surprise position stats across 
                                        mice, structured as 
                                           plane/line x session x stats
            ['mouse_pos_stats'] (list): surprise position stats across 
                                        sequences, structured as 
                                            plane/line x mouse x session 
                                                x  stats
            ['linpla_ord'] (list)      : order list of planes/lines
        if datatype == 'roi':
            ['pos_stats_grped'] (list): surprise position stats across 
                                        sequences (ROIs grouped across mice), 
                                        structured as 
                                            plane/line x session x stats

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
    if parallel:
        outs = Parallel(n_jobs=n_jobs)(delayed(prog_by_sesses)(
            sessions, analyspar, stimpar, datatype, surp, position, baseline, 
            seq_st=True, diff=True)
            for sessions in linpla_sess)
    else:
        outs = []
        for sessions in linpla_sess:
            outs.append(prog_by_sesses(sessions, analyspar, stimpar, 
                datatype, surp, position, baseline, seq_st=True, diff=True))
    outs = [list(out) for out in zip(*outs)]

    pos_info = dict()
    if datatype == 'roi':
        [mouse_seq_st, all_seq_st, grped_seq_st, sess_info] = outs
        pos_info['pos_stats_grped'] = grped_seq_st
        
    elif datatype == 'run':
        [mouse_seq_st, all_seq_st, sess_info] = outs
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    pos_info['pos_stats']        = all_seq_st
    pos_info['mouse_pos_stats']  = mouse_seq_st
    pos_info['linpla_ord']       = linpla_order

    return pos_info, sess_info


#############################################
def stim_idx_by_linpla(sessions, analyspar, stimpar, permpar, datatype='roi', 
                       feature='bysurp', position=0, seed=None, parallel=False):
    """
    stim_idx_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing stimulus indices for ROIs or running, across 
    sessions, as well as session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters  
        - permpar (PermPar)    : named tuple containing permutation parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - feature (str)         : how to split data, either 
                                  'bysurp'  : surprise vs regular sequences
                                  'progsurp': surp, vs preceeding reg, 
                                      but not locked (e.g., E, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  'progreg': reg, vs preceeding surp, 
                                      but not locked (e.g., D, vs prev E)
                                      (i.e., pre not necessarily equal to post)
                                  'dir': left vs right (Bricks)
                                  default: 'bysurp'
        - position (int)        : surprise or regular position to retrieve
                                  default: 0
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - idx_info (dict)   : dictionary with feature index info
            ['item_idxs'] (list) : feature index bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ['item_percs'] (list): feature percentile bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ['rand_idxs'] (list) : random feature index bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ['bin_edges'] (list) : data edges for indices, structured as 
                                       plane/line x session x [min, max]
            ['linpla_ord'] (list): order list of planes/lines

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    args_list = [analyspar, stimpar, permpar.n_perms, permpar.p_val, datatype, 
        feature, position, seed, False]


    lp_item_idxs, lp_item_percs, lp_rand_idxs, lp_bin_edges, sess_info = \
        gen_util.parallel_wrap(
            stim_idx_by_sesses, linpla_sess, args_list, parallel=parallel, 
            zip_output=True)

    idx_info = dict()

    idx_info['item_idxs']     = lp_item_idxs
    idx_info['item_percs']    = lp_item_percs
    idx_info['rand_idxs']     = lp_rand_idxs
    idx_info['bin_edges']     = lp_bin_edges
    idx_info['linpla_ord']    = linpla_order

    return idx_info, sess_info


#############################################
def run_surp_idx(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                 permpar, figpar, datatype='roi', parallel=False):
    """
    run_surp_idx(sessions, analysis, analyspar, sesspar, stimpar, 
                 permpar, figpar)

    Retrieves surprise indices for each item (ROI or 1 running item) and plots 
    progression within a session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')

    if not analyspar.scale:
        print('Setting analyspar.scale to True.')
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, 'scale', True)

    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise indices for {datastr} '
        f'\n({sessstr_pr}{dendstr_pr}).')
    
    position = 0

    surpidx_info, sess_info = stim_idx_by_linpla(
        sessions, analyspar, stimpar, permpar, datatype, feature='bysurp', 
        position=position, seed=seed, parallel=parallel)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                'seed'    : seed,
                }

    info = {'analyspar'   : analyspar._asdict(),
            'sesspar'     : sesspar._asdict(),
            'stimpar'     : stimpar._asdict(),
            'permpar'     : permpar._asdict(),
            'extrapar'    : extrapar,
            'sess_info'   : sess_info,
            'surpidx_info': surpidx_info
            }

    fulldir, savename = acr_sess_plots.plot_surp_idx(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')
    

#############################################
def run_direction_idx(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                      permpar, figpar, datatype='roi', parallel=False):
    """
    run_direction_idx(sessions, analysis, analyspar, sesspar, stimpar, 
                      permpar, figpar)

    Retrieves direction indices for each item (ROI or 1 running item) and plots 
    progression within a session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    if stimpar.stimtype != 'bricks':
        print('direction index analysis can only be run on Bricks.')
        return

    if stimpar.bri_dir != 'both':
        print('Setting stimpar.bri_dir to `both`.')
        stimpar = sess_ntuple_util.get_modif_ntuple(stimpar, 'bri_dir', 'both')

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')

    if not analyspar.scale:
        print('Setting analyspar.scale to True.')
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, 'scale', True)

    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting direction indices for {datastr} '
        f'\n({sessstr_pr}{dendstr_pr}).')

    diridx_info = []
    sess_info = []
    for direc in ['dir_reg', 'dir_surp']:
        diridx_info_sub, sess_info_sub = stim_idx_by_linpla(
            sessions, analyspar, stimpar, permpar, datatype, feature=direc, 
            seed=seed, parallel=parallel)
        diridx_info.append(diridx_info_sub)
        sess_info.append(sess_info_sub)
    
    if sess_info[0] != sess_info[1]:
        raise NotImplementedError('Did not expect different `sess_info`.')
    else:
        sess_info = sess_info[0]

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                'seed'    : seed,
                }

    info = {'analyspar'  : analyspar._asdict(),
            'sesspar'    : sesspar._asdict(),
            'stimpar'    : stimpar._asdict(),
            'permpar'    : permpar._asdict(),
            'extrapar'   : extrapar,
            'sess_info'  : sess_info,
            'diridx_info': diridx_info
            }

    fulldir, savename = acr_sess_plots.plot_direction_idx(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')
    

#############################################
def run_prog(sessions, analysis, analyspar, sesspar, stimpar, figpar, 
             datatype='roi', parallel=False):
    """
    run_prog(sessions, analysis, analyspar, sesspar, stimpar, figpar)

    Retrieves difference between surprise response, and the 
    preceeding regular response (and v.v.), and plots progression within a 
    session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 'g')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting progression of surprise v '
        f'previous regular {datastr} response (and v.v.) '
        f'\n({sessstr_pr}{dendstr_pr}).')

  
    max_n_surp = 4
    positions = np.arange(max_n_surp)

    for position in positions:
        all_sess_info = []
        all_prog_info = []
        print(f'\nFor position {position}.')      
        for lock in ['progsurp', 'progreg']:
            prog_info, sess_info = prog_by_linpla(
                sessions, analyspar, stimpar, datatype, surp=lock, 
                baseline=0, position=position, parallel=parallel)
            all_prog_info.append(prog_info)
            all_sess_info.append(sess_info)

        extrapar = {'analysis': analysis,
                    'datatype': datatype,
                    'position': sess_str_util.get_position_name(position),
                    }

        info = {'analyspar'  : analyspar._asdict(),
                'sesspar'    : sesspar._asdict(),
                'stimpar'    : stimpar._asdict(),
                'extrapar'   : extrapar,
                'sess_info'  : all_sess_info,
                'prog_info'  : all_prog_info
                }

        fulldir, savename = acr_sess_plots.plot_prog(figpar=figpar, **info)
        file_util.saveinfo(info, savename, fulldir, 'json')
    

#############################################
def run_position(sessions, analysis, analyspar, sesspar, stimpar, figpar, 
                 datatype='roi', parallel=False):
    """
    run_position(sessions, analysis, analyspar, sesspar, stimpar, figpar)

    Retrieves difference response to surprise in each position (first, second, 
    third), and the preceeding regular response (and v.v.), and plots 
    progression across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 'o')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.bri_dir, 
        stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting progression of surprise v '
        f'previous regular {datastr} response (and v.v.) across sessions '
        f'\n({sessstr_pr}{dendstr_pr}).')

    max_n_surp = 4
    positions = np.arange(max_n_surp)

    for position in positions:
        all_sess_info = []
        all_pos_info = []
        print(f'\nFor position {position}.')      
        for lock in ['progsurp', 'progreg']:
            pos_info, sess_info = position_by_linpla(
                sessions, analyspar, stimpar, datatype, surp=lock, 
                baseline=0, position=position, parallel=parallel)
            all_pos_info.append(pos_info)
            all_sess_info.append(sess_info)

        extrapar = {'analysis': analysis,
                    'datatype': datatype,
                    'position': sess_str_util.get_position_name(position),
                    }

        info = {'analyspar'  : analyspar._asdict(),
                'sesspar'    : sesspar._asdict(),
                'stimpar'    : stimpar._asdict(),
                'extrapar'   : extrapar,
                'sess_info'  : all_sess_info,
                'pos_info'   : all_pos_info
                }

        fulldir, savename = acr_sess_plots.plot_position(figpar=figpar, **info)
        file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def get_rise_latency(data_arr, xran, method='ttest', p_val_thr=0.005, 
                     stats='mean', rel_std=0.5, pad_win=0):
    """
    get_rise_latency(data_arr, xran)

    Returns rise latency values for each item (e.g., ROI) to reach threshold.

    Required args:
        - data_arr (3D array): data array, structured as 
                               item (e.g., ROI) x sequences x frames
                               (padded if pad_win != 0)
        - xran (list)        : latency values in seconds for each frame 
                               (padded)

    Optional args:
        - method (str)     : method to use to determine latency
                             'ttest': first point higher than start point that 
                                      reaches p-value
                             'ratio': first point higher than start point by a 
                                      certain ratio of standard deviations 
                             default: 'ttest'
        - p_val_thr (float): threshold p value to use for t-test method
                             default: 0.005 
        - stats (str)      : statistic to take for starting point for ratio 
                             method
                             default: 'mean'
        - rel_std (float)  : threshold standard deviation ratio to use to for 
                             ratio method
                             default: 0.5
        - pad_win (int)    : number of padding frames used to smooth and 
                             augment data
                             default: 0

    Returns:
        - lat_vals (list): latency values (for all items that reach threshold 
                           for a peak latency to be determined)
        - roi_ns (list)  : numbers of ROIs that reached threshold
    """


    if len(data_arr.shape) != 3:
        raise ValueError('Data array must be 3 dimensions.')
    
    fr_axis = len(data_arr.shape) - 1

    if pad_win:
        if pad_win%2 == 0:
            raise NotImplementedError('Using an even padding window may '
                'not work as expected as it is not symmetrical around '
                'each point.') 
        # stack shifted array to combine 3 points for each point estimate
        pad_fr = pad_win//2
        n_fr = data_arr.shape[-1]
        data_stack = [data_arr[gen_util.slice_idx(
            fr_axis, slice(i, n_fr + i - pad_win + 1))] for i in range(pad_win)]
        # concatenate sequences to augment and smooth data
        data_arr = np.concatenate(data_stack, axis=fr_axis - 1)
        xran = xran[pad_fr : -pad_fr]

    if method == 'ratio':
        # stats (x ROI) x frame
        data_st = math_util.get_stats(
            data_arr, stats=stats, error='std', axes=1, nanpol='omit')
        all_med = data_st[0]
        med_st = data_st[0][gen_util.slice_idx(fr_axis - 1, 0)].reshape(-1, 1)
        stat_dev = data_st[1][gen_util.slice_idx(fr_axis - 1, 0)].reshape(-1, 1)
        rat = (all_med - med_st)/stat_dev # rel strength of signal                    
    
    roi_ns = []
    lat_vals = []
    for r in range(len(data_arr)):
        if method == 'ratio':
            r_idx = np.argmax(rat[r] > rel_std)
        elif method == 'ttest':
            r_idx = 0 
            for p in range(1, data_arr.shape[-1]):
                t_stat, p_val = scist.ttest_rel(
                    data_arr[r, :, 0], data_arr[r, :, p], axis=None)
                if t_stat > 0 and p_val < p_val_thr:
                    r_idx = p
                    break
        else:
            gen_util.accepted_values_error('method', method, ['ratio', 'ttest'])
        if r_idx == 0: # if never peaks, skips to nan
            continue
        else:
            roi_ns.append(r)
            lat_vals.append(xran[r_idx])

    return lat_vals, roi_ns


#############################################
def get_sess_latencies(sess, analyspar, stimpar, latpar, permpar=None, 
                       seed=None, datatype='roi'):
    """
    get_sess_latencies(sess, analyspar, stimpar)

    Returns latency values for the session.

    Required args:
        - sess (Session object): session object (can be None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple containing latency parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.surp_resp is True.
                             default: None
        - seed (int)       : seed value to use. (-1 treated as None)
                             default: None
        - datatype (str)   : type of data (e.g., 'roi', 'run')
                             default: 'roi'

    Returns:
        - lat_vals (list)   : latency values for the session or None if no 
                              session (None if no session)
        - roi_ns (list)     : numbers of ROIs that reached threshold
        if latpar.surp_resp:
        - signif_rois (list): numbers of ROIs that showed significant surprise 
                              responses
    """

    if datatype == 'run' and latpar.surp_resp:
        raise ValueError('cannot set latpar.surp_resp to True if running data.')

    if sess is None:
        return [None, []] + [[]] * latpar.surp_resp
    stim = sess.get_stim(stimpar.stimtype)
    remconsec = (stimpar.stimtype == 'bricks')
    surps = [1]
    if latpar.surp_resp:
        if stimpar.stimtype == 'bricks':
            surps = [1, 1]
            pre_posts = [[1.0, 0], [0, 1.0]]    
        elif stimpar.stimtype == 'gabors':
            surps = [0, 1]
            pre_posts = [[0, 0.45]] * 2
        else:
            gen_util.accepted_values_error('stimpar.stimtype', 
                stimpar.stimtype, ['bricks', 'gabors'])

    all_segs = [stim.get_segs_by_criteria(gabfr=stimpar.gabfr, 
        gabk=stimpar.gabk, gab_ori=stimpar.gab_ori, bri_dir=stimpar.bri_dir, 
        bri_size=stimpar.bri_size, surp=surp, by='seg', remconsec=remconsec) 
        for surp in surps]

    if analyspar.remnans:
        nanpol = None
    else:
        nanpol = 'omit'

    if datatype == 'roi':
        twop_frs = [stim.get_twop_fr_by_seg(segs, first=True)['first_twop_fr']
            for segs in all_segs]
        # array: ROI x sequences x frames
        # pad with one frame before and after
        pad_win = 3
        pad = (pad_win//2, pad_win//2)
        # get data for last surps value,  xran is padded
        roi_data_df = stim.get_roi_data(
            twop_frs[-1], stimpar.pre, stimpar.post, fluor=analyspar.fluor, 
            remnans=analyspar.remnans, scale=analyspar.scale, pad=pad
            ) #, smooth=win_pad)
        xran = roi_data_df.index.unique('time_values').to_numpy() 
        data_arr = gen_util.reshape_df_data(roi_data_df, squeeze_cols=True)  
        # identify surprise responsive ROIs
        if latpar.surp_resp:
            if permpar is None:
                raise ValueError('Must pass a `permpar` if latpar.surp_resp.')
            elif permpar.tails != 'up':
                raise ValueError('permpar.tails must be `up`.')
            seed = gen_util.seed_all(seed, 'cpu', print_seed=False)
            # full_arr: 'surp x ROI x sequences'
            integ_data = [gen_util.reshape_df_data(stim.get_roi_data(
                twop_fr, pre=pre, post=post, fluor=analyspar.fluor, integ=True,
                remnans=analyspar.remnans, scale=analyspar.scale)['roi_traces'], 
                squeeze_cols=True)
                for twop_fr, [pre, post] in zip(twop_frs, pre_posts)]   
            signif_rois = signif_grps.get_signif_rois(
                integ_data, permpar, stats=analyspar.stats, op='diff', 
                nanpol=nanpol, print_rois=False)
            data_arr = data_arr[signif_rois]

    elif datatype == 'run':
        # array: 1 x sequences x frames
        stim_fr = stim.get_stim_fr_by_seg(
            all_segs[-1], first=True)['first_stim_fr']
        run_data_df = stim.get_run_data(
            stim_fr, stimpar.pre, stimpar.post, remnans=analyspar.remnans, 
            scale=analyspar.scale)['run_velocity']
        # padding not implemented for running data
        pad_win = 0
        xran = run_data_df.index.unique('time_values').to_numpy()
        data_arr = np.expand_dims(run_data_df.unstack().to_numpy(), 0)
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    lat_vals, roi_ns = get_rise_latency(
        data_arr, xran, method=latpar.method, p_val_thr=latpar.p_val_thr, 
        stats=analyspar.stats, rel_std=latpar.rel_std, pad_win=pad_win)
    if latpar.surp_resp:
        # retrieve original roi_ns based on signif_rois
        roi_ns = list(np.asarray(signif_rois)[roi_ns])
        return lat_vals, roi_ns, signif_rois
    else:
        return lat_vals, roi_ns


#############################################
def run_surp_latency(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                     latpar, figpar, permpar=None, datatype='roi', 
                     parallel=False):
    """
    run_surp_latency(sessions, analysis, analyspar, sesspar, stimpar, 
                     figpar)

    Retrieves area values by session x surp val, locked to surprise onset and 
    plots statistics across ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.surp_resp is True.
                             default: None
        - datatype (str)   : type of data (e.g., 'roi', 'run')
                             default: 'roi'
        - parallel (bool)  : if True, some of the analysis is run in parallel 
                             across CPU cores 
                             default: False
    """

    if latpar.surp_resp:
        if datatype == 'run':
            print('Setting latpar.surp_resp to False as datatype is run.')
            latpar = sess_ntuple_util.get_modif_ntuple(
                latpar, 'surp_resp', False)
        elif permpar is None:
            raise ValueError('Must pass a `permpar` if latpar.surp_resp.')
        elif permpar.tails != 'up':
            print('Setting permpar.tails to `up`.')
            permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'tails', 'up')

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.bri_dir, stimpar.bri_size, stimpar.gabk, 'print')
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    stat_len = 2 + (analyspar.error == 'std')

    print(f'\nAnalysing and plotting surprise latency for {datastr} traces '
        f' \n({sessstr_pr}{dendstr_pr}).')

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)

    [all_lat_stats, all_lat_vals, 
     all_lat_p_vals, all_lat_vals_flat] = [], [], [], []
    all_sess_info = []

    all_n_sign_rois = []
    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_lat_vals, l_lat_vals_flat, l_sess_info = [], [], []
        l_lat_stats = np.full([stat_len, len(l_sesses)], np.nan)
        l_n_sign_rois = []
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(
                sesses, analyspar.fluor, add_none=True, 
                incl_roi=(datatype=='roi')))
            # for each mouse
            n_jobs = gen_util.get_n_jobs(len(l_sesses), parallel=parallel)
            if parallel:
                sess_vals = Parallel(n_jobs=n_jobs)(delayed(
                    get_sess_latencies)(sess, analyspar, stimpar, latpar, 
                    permpar, seed, datatype) for sess in sesses)
                sess_lat_vals = [vals[0] for vals in sess_vals]
                if latpar.surp_resp:
                    sess_n_sign_rois = [len(vals[2]) for vals in sess_vals]
            else:
                sess_lat_vals = []
                sess_n_sign_rois = []
                for sess in sesses:
                    vals = get_sess_latencies(
                        sess, analyspar, stimpar, latpar, permpar, seed, 
                        datatype)
                    sess_lat_vals.append(vals[0])
                    if latpar.surp_resp:
                        sess_n_sign_rois.append(vals[2])
            # all values across mice for the session
            lat_vals_flat = np.asarray(
                [val for sub_vals in sess_lat_vals if sub_vals is not None
                for val in sub_vals])
            l_lat_stats[:, s] = math_util.get_stats(
                lat_vals_flat, analyspar.stats, analyspar.error, nanpol='omit')
            l_lat_vals_flat.append(lat_vals_flat)
            l_lat_vals.append(sess_lat_vals)
            if latpar.surp_resp:
                l_n_sign_rois.append(sess_n_sign_rois)

        p_vals = math_util.comp_vals_acr_groups(
            l_lat_vals_flat, n_perms=permpar.n_perms, 
            stats=analyspar.stats).tolist()

        all_sess_info.append(l_sess_info)
        all_lat_stats.append(l_lat_stats.tolist())
        all_lat_vals_flat.append(l_lat_vals_flat)
        all_lat_vals.append(l_lat_vals)
        all_lat_p_vals.append(p_vals)
        if latpar.surp_resp:
            all_n_sign_rois.append(l_n_sign_rois)


    # compare across planes in a line
    lin_p_vals = comp_vals_acr_planes(
        linpla_ord, all_lat_vals_flat, permpar.n_perms, stats=analyspar.stats)

    n_sess = len(all_lat_vals_flat[0])
    tot_n_comps, max_comps_per = get_n_comps(all_lat_p_vals, n_sess, lin_p_vals)
    
    lat_data = {'linpla_ord'   : linpla_ord,
                'lat_stats'    : all_lat_stats,
                'lat_vals'     : all_lat_vals,
                'lat_p_vals'   : all_lat_p_vals,
                'lin_p_vals'   : lin_p_vals.tolist(),
                'tot_n_comps'  : tot_n_comps,
                'max_comps_per': max_comps_per
                }

    if latpar.surp_resp:
        lat_data['n_sign_rois'] = all_n_sign_rois

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar': analyspar._asdict(),
            'sesspar'  : sesspar._asdict(),
            'stimpar'  : stimpar._asdict(),
            'latpar'   : latpar._asdict(),
            'extrapar' : extrapar,
            'sess_info': all_sess_info,
            'lat_data' : lat_data
            }
    
    if latpar.surp_resp:
        info['permpar']  = permpar
        extrapar['seed'] = seed

    fulldir, savename = acr_sess_plots.plot_surp_latency(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def run_resp_prop(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                  latpar, figpar, permpar=None, parallel=False):
    """
    run_resp_prop(sessions, analysis, analyspar, sesspar, stimpar, latpar,
                  figpar)

    Retrieves proportion of ROIs that show a response to surprise within a 
    limited latency for both stimuli and plots statistics across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 'p')
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.surp_resp is True.
                             default: None
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    datatype = 'roi'

    if latpar.surp_resp:
        if permpar is None:
            raise ValueError('Must pass a `permpar` if latpar.surp_resp.')
        elif permpar.tails != 'up':
            print('Setting permpar.tails to `up`.')
            permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'tails', 'up')

    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        'roi', 'print')

    print('\nAnalysing and plotting proportion of surprise responsive ROIs'
        f'{dendstr_pr}.')

    if stimpar.stimtype != 'both':
        raise ValueError('stimpar.stimtype must be `both` for this analysis.')
    stimtypes  = ['gabors', 'gabors', 'bricks']
    gabfrs     = [3, 1, 'none']
    comb_names = ['gabfrs', 'surps']
    combs      = [[0, 1] , [0, 2]]

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)

    all_sess_info = []
    all_prop_stats = []
    all_n_sign_rois = []
    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_sess_info = []
        l_prop_stats = []
        l_n_sign_rois = []
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(sesses, 
                analyspar.fluor, add_none=True, incl_roi=(datatype=='roi')))
            # keep only sessions with both stimuli
            sesses = sess_gen_util.check_both_stimuli(sesses)
            nrois = [sess.get_nrois(analyspar.remnans, analyspar.fluor) 
                for sess in sesses]
            resp_arrs = [np.full([len(stimtypes), nroi], 0) for nroi in nrois]         
            for s, (stimtype, gabfr) in enumerate(zip(stimtypes, gabfrs)):
                stimpar_spec = sess_ntuple_util.get_modif_ntuple(
                    stimpar, ['stimtype', 'gabfr'], [stimtype, gabfr])
                # for each mouse
                n_jobs = gen_util.get_n_jobs(len(l_sesses), parallel=parallel)
                if parallel:
                    sess_vals = Parallel(n_jobs=n_jobs)(delayed(
                        get_sess_latencies)(sess, analyspar, stimpar_spec, 
                        latpar, permpar, seed, datatype) for sess in sesses)
                    sess_roi_ns = [vals[1] for vals in sess_vals]
                    if latpar.surp_resp:
                        sess_n_sign_rois = \
                            [len(vals[2]) for vals in sess_vals]             
                else:
                    sess_roi_ns = []
                    sess_n_sign_rois = []
                    for sess in sesses:
                        vals = get_sess_latencies(
                            sess, analyspar, stimpar, latpar, permpar, seed, 
                            datatype)
                        sess_roi_ns.append(vals[1])
                        if latpar.surp_resp:
                            sess_n_sign_rois.append(vals[2])
                for r, roi_ns in enumerate(sess_roi_ns):
                    if len(roi_ns) > 0:
                        resp_arrs[r][s, np.asarray(roi_ns)] = 1
            resp_prop_stats = []
            for comb in combs:
                comb_props = []
                for nroi, resp_arr in zip(nrois, resp_arrs):
                    if nroi == 0:
                        continue
                    resp_same = resp_arr[comb[0]] == resp_arr[comb[1]]
                    comb_props.append(sum(resp_same)/float(nroi))
                resp_prop_me = math_util.mean_med(
                    comb_props, stats=analyspar.stats, nanpol='omit')
                resp_prop_de = math_util.error_stat(
                    comb_props, stats=analyspar.stats, error=analyspar.error, 
                    nanpol='omit')
                resp_prop_stats.append([resp_prop_me, resp_prop_de])
                l_prop_stats.append(resp_prop_stats)
                if latpar.surp_resp:
                    l_n_sign_rois.append(sess_n_sign_rois)
        all_prop_stats.append(l_prop_stats)
        all_sess_info.append(l_sess_info)
        if latpar.surp_resp:
            all_n_sign_rois.append(l_n_sign_rois)

    prop_data = {'linpla_ord': linpla_ord,
                 'prop_stats': all_prop_stats,
                 'comb_names': comb_names
                }

    if latpar.surp_resp:
        prop_data['n_sign_rois'] = all_n_sign_rois

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'latpar'    : latpar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'prop_data' : prop_data
            }

    if latpar.surp_resp:
        info['permpar']  = permpar
        extrapar['seed'] = seed

    fulldir, savename = acr_sess_plots.plot_resp_prop(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')

