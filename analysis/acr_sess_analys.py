"""
acr_sess_analys.py

This script runs analyses across sessions using a Session object with data 
generated by the AIBS experiments for the Credit Assignment Project.

Authors: Colleen Gillon

Date: October, 2019

Note: this code uses python 3.7.

"""

import copy

from joblib import Parallel, delayed
import numpy as np
import scipy.stats as scist

from . import pup_analys, ori_analys, quint_analys, signif_grps
from util import file_util, gen_util, math_util
from sess_util import sess_gen_util, sess_ntuple_util, sess_str_util
from plot_fcts import acr_sess_analysis_plots as acr_sess_plots



#############################################
def split_by_linpla(sessions, rem_empty=False):
    """
    split_by_linpla(sessions)

    Returns nested list of sessions organized by line/plane.

    Required args:
        - sessions (list): nested list of Session objects (mouse x sess)

    Optional args:
        - rem_empty (bool): if True, line/planes with no sessions are omitted
                            default: False

    Returns:
        - linpla_sess (list) : nested list of Session objects 
                               (linpla x mouse x sess) (None for missing 
                               sessions)
        - linpla_order (list): line x plane order
    """

    lines   = ['L2/3', 'L5']
    planes  = ['dendrites', 'soma']
    linpla_order = [f'{lin} {pla[:4]}' for pla in planes for lin in lines]
    linpla_strip = [s.replace('/', '') for s in linpla_order]
    
    linpla_sess = [[] for _ in range(len(linpla_order))] # linpla x mice x sess
    for mouse_sess in sessions:
        line = list(set([sess.line for sess in mouse_sess if sess is not None]))
        if len(line) != 1:
            raise ValueError('Error - why multiple lines? (or None?)')
        else:
            line = line[0][:3].strip('-')
        
        plas = [sess.plane for sess in mouse_sess if sess is not None]
        pla_vals = list(set(plas))

        for pla in pla_vals:
            sesses = []
            for sess in mouse_sess:
                if sess is None or sess.plane != pla:
                    sesses.append(None)
                else:
                    sesses.append(sess)             
            if list(set(sesses)) != [None]: # only add if it's not all None
                idx = linpla_strip.index(f'{line} {pla}')
                linpla_sess[idx].append(sesses)

    # check for empty lists in any lin/pla
    if rem_empty:
        rem_idx = []
        for l, sessions in enumerate(linpla_sess):
            if len(sessions) == 0:
                rem_idx.append(l)
        linpla_order = gen_util.remove_idx(linpla_order, rem_idx)
        linpla_sess = gen_util.remove_idx(linpla_sess, rem_idx)

    return linpla_sess, linpla_order


#############################################
def define_baseline(stimtype='bricks', gabfr=3, baseline=0.1, pre=1.5, 
                    post=1.5):
    """
    define_baseline()

    Returns baseline times based on stimulus type and times. For gabors, the
    baseline is before onset of the earliest D/E frame in the stimulus period. 
    For bricks, the baseline is before the onset of the stimulus period.

    Optional args:
        - stimtype (str)  : stimulus ('bricks' or 'gabors')
                            default: 'bricks'
        - gabfr (int)     : gabor frame at which stimulus period start 
                            (0, 1, 2, 3) (or to include, for GLM)
                            default: 0
        - baseline (float): baseline length (in sec)
                            default: 0.1
        - pre (float)     : range of frames included in stimulus period before 
                            each reference frame (in s)
                            default: 1.5 (in sec)
        - post (float)    : range of frames included in stimulus period after 
                            each reference frame (in s)
                            default: 1.5 (in sec)

    Returns:
        - pre (float)     : range of frames in stimulus period before each 
                            reference frame included in baseline (in s)
        - post (float)    : range of frames in stimulus period after each 
                            reference frame included in baseline (in s)
    """

    if stimtype == 'bricks': # before seq onset # NOT A GREAT OPTION
        base_pre = pre + baseline
    elif stimtype == 'gabors':
        sec_per, targ_fr, full = 0.3, 3, 1.5
        base_pre = pre - baseline - (sec_per * (targ_fr - gabfr) + pre)%full
    base_post = baseline - base_pre

    return base_pre, base_post


#############################################
def surp_data_by_sess(sess, analyspar, stimpar, datatype='roi', surp='bysurp', 
                      stats='mean', integ=False, baseline=0.1):
    """
    surp_data_by_sess(sess, analyspar, stimpar)

    Returns regular and surprise data for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp
                                  default: 'bysurp'
        - stats (str)           : statistic to use ('mean' or 'median')
                                      default: 'mean'
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.1

    Returns:
        - data_arr (list): list of data arrays structured as 
                           reg, surp [x ROIs] x seq [x frames]
                           (or surp, reg if surp == 'reglock')
    """

    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('stimpar.pre must equal stimpar.post for '
                         'this locked analysis.')
    locks = ['reglock', 'surplock'] # ordered in surp == [0, 1] order

    stim = sess.get_stim(stimpar.stimtype)
    data_arr = []

    if surp == 'bysurp':
        segs = [stim.get_segs_by_criteria(gabfr=stimpar.gabfr,
                     gabk=stimpar.gabk, gab_ori=stimpar.gab_ori,
                     bri_dir=stimpar.bri_dir, bri_size=stimpar.bri_size,
                     surp=s, by='seg') for s in [0, 1]]
        pre_posts = [[stimpar.pre, stimpar.post]] * 2        
    elif surp in locks:
        surp_val = locks.index(surp)
        segs = stim.get_segs_by_criteria(gabfr='any',
                    gabk=stimpar.gabk, gab_ori=stimpar.gab_ori,
                    bri_dir=stimpar.bri_dir, bri_size=stimpar.bri_size,
                    surp=surp_val, by='seg', remconsec=True)
        # shift to correct gabor frame
        if stimpar.stimtype == 'gabors' and stimpar.gabfr not in ['any', 'all']:
            segs = [seg + stimpar.gabfr for seg in segs]
        segs = [segs] * 2
        pre_posts = [[stimpar.pre, 0], [0, stimpar.post]]
    else:
        gen_util.accepted_values_error('surp', surp, ['bysurp', 'surplock', 
                                       'reglock'])
    # get regular, then surprise
    args = {'remnans': analyspar.remnans,
            'stand'  : analyspar.scale}
    
    if analyspar.remnans:
        nanpol = None
    else:
        nanpol = 'omit'

    for subsegs, [pre, post] in zip(segs, pre_posts):
        ch_fl = None
        if baseline:
            # for surp in locks, takes different baselines for pre and post 
            # sequences
            base_pre, base_post = define_baseline(stimpar.stimtype, 
                                         stimpar.gabfr, baseline, pre, post)
            ch_fl = [np.max([pre, base_pre]), np.max([post, base_post])]
        elif surp in locks:
            # check flanks as pre and post are split up!
            ch_fl = [stimpar.pre, stimpar.post]
        if datatype == 'roi':
            fr_ns = stim.get_twop_fr_by_seg(subsegs, first=True, ch_fl=ch_fl)
            fct = stim.get_roi_trace_array
            args['fluor'] = analyspar.fluor
        elif datatype == 'run':
            # array: 1 x sequences
            fr_ns = stim.get_stim_fr_by_seg(subsegs, first=True, ch_fl=ch_fl)
            fct = stim.get_run_array
        else:
            gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

        data_arr.append(fct(fr_ns, pre, post, **args)[1])
        
        if baseline:
            base_data = fct(fr_ns, base_pre, base_post, **args)[1]
            end_shape = list(base_data.shape)[:-1] + [1]
            # (ROI x) sequences x frames
            base_data = math_util.mean_med(base_data, stats=stats, axis=-1, 
                                    nanpol=nanpol)
            data_arr[-1] = data_arr[-1] - base_data.reshape(end_shape)
        if integ:
            data_arr[-1] = math_util.integ(data_arr[-1], 1./sess.twop_fps, 
                                     axis=-1, nanpol=nanpol)

    return data_arr


#############################################
def surp_diff_by_sess(sess, analyspar, stimpar, n_perms=1000, datatype='roi', 
                      surp='bysurp', baseline=0.1):
    """
    surp_diff_by_sess(sess, analyspar, stimpar)
    
    Returns session statistics for difference between surprise and regular
    sequences as well as random values obtained from permutations.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp, or
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1


    Returns:
        - diff_st (1D array) : session statistics for difference between 
                               surp and regular sequence areas (or vice versa 
                               for surp == 'reglock') (me, err)
        - all_rand (1D array): random value obtained for each permutation
    """

    nanpol = 'omit'
    if analyspar.remnans:
        nanpol = None

    data_arr = surp_data_by_sess(sess, analyspar, stimpar, datatype=datatype, 
                                 surp=surp, stats=analyspar.stats, integ=True, 
                                 baseline=baseline)
    
    # take mean/median across sequences
    mean_meds = [math_util.mean_med(data, stats=analyspar.stats, axis=-1, 
                           nanpol=nanpol) for data in data_arr]
    diff_st = math_util.get_stats(mean_meds[1] - mean_meds[0], 
                        stats=analyspar.stats, error=analyspar.error, 
                        nanpol=nanpol)

    # get CI
    div = data_arr[1].shape[1] # length of surp
    # perms
    all_rand = math_util.mean_med(math_util.permute_diff_ratio(
                    np.concatenate([data_arr[1], data_arr[0]], axis=-1), 
                    div=div, n_perms=n_perms, stats=analyspar.stats, 
                    nanpol=nanpol, op='diff'), stats=analyspar.stats, axis=0, 
                    nanpol=nanpol)

    return diff_st, all_rand



#############################################
def surp_diff_by_sesses(sessions, analyspar, stimpar, permpar, datatype='roi', 
                        surp='bysurp', baseline=0.1):
    """
    surp_diff_by_sesses(sessions, analyspar, stimpar, permpar)

    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp'  : all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg
                                  'reglock' : first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1

    Returns:
        - mouse_diff_st (list)   : difference statistics across ROIs or seqs, 
                                   structured as mouse x session x stats
        - all_diff_st (list)     : difference stats across mice, 
                                   structured as session x stats
        - CI_vals (list)         : CIs values, structured as 
                                   session x perc (med, lo, high)
        - sign_sess (list)       : significant session indices, optionally
                                   structured by tail
        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
                         'each mouse.')
    n_sess = n_sess[0]

    st_len = 2 + (analyspar.stats == 'median' and analyspar.error == 'std')
    percs = [50.0] + math_util.get_percentiles(CI = (1.0 - permpar.p_val))[0]

    n_mice = len(sessions)
    mouse_diff_st = np.empty([n_mice, n_sess, st_len]) * np.nan
    all_rand = np.empty([n_mice, n_sess, permpar.n_perms]) * np.nan
    sess_info = []
    for m, m_sess in enumerate(sessions):
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(m_sess, analyspar.fluor, 
                                    add_none=True)
        for s, sess in enumerate(m_sess):
            if sess is None:
                continue
            [mouse_diff_st[m, s], 
             all_rand[m, s]] = surp_diff_by_sess(sess, analyspar, stimpar, 
                                  n_perms=permpar.n_perms, datatype=datatype, 
                                  surp=surp, baseline=baseline)            
        sess_info.append(m_sess_info)

    # take stats across mice
    all_diff_st = math_util.get_stats(mouse_diff_st[:, :, 0], 
                        stats=analyspar.stats, error=analyspar.error, 
                        axes=0, nanpol='omit').T # sess x stats

    all_diff_st_modif = all_diff_st # for NaN replacement
    all_diff_st = all_diff_st.tolist() # do before NaN modif

    # take mean/median across mice (sess x perms)
    all_rand = math_util.mean_med(all_rand, stats=analyspar.stats, 
                                  axis=0, nanpol='omit')
    
    # get CI (sess x percs)
    CI_vals = np.asarray([np.percentile(all_rand, p, axis=-1) 
                          for p in percs]).T.tolist()

    # get significant session numbers (optionally by tails)
    nan_idx = np.where(~np.isfinite(np.sum(all_rand, axis=1)))[0]
    all_diff_st_modif[nan_idx, 0] = 1 # to avoid NaN problem
    all_rand[nan_idx] = 1 # to avoid NaN problem
    sign_sess = math_util.id_elem(all_rand, all_diff_st_modif[:, 0], 
                            tails=permpar.tails, p_val=permpar.p_val, 
                            min_n=25)
                            
    mouse_diff_st = mouse_diff_st.tolist()    

    return mouse_diff_st, all_diff_st, CI_vals, sign_sess, sess_info


#############################################
def surp_diff_by_linpla(sessions, analyspar, stimpar, permpar, datatype='roi', 
                        surp='bysurp', baseline=0.1, parallel=False):
    """
    surp_diff_by_linpla(sessions, analyspar, stimpar, permpar)
    
    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)         : type of data (e.g., 'roi', 'run')
                                   default: 'roi'
        - surp (str)             : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp, or                           
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False

    Returns:
        - diff_info (dict)       : dictionary with difference info
            ['all_diff_stats'] (list)  : difference stats across mice, 
                                         structured as plane/line x session 
                                                                  x stats
            ['mouse_diff_stats'] (list): difference statistics across ROIs or 
                                         seqs, structured as 
                                             plane/line x mouse x session 
                                                        x stats
            ['CI_vals'] (list)         : CIs values, structured as
                                             plane/line x session 
                                                        x perc (med, lo, high)
            ['sign_sess'] (list)       : significant session indices, 
                                         structured as plane/line (x tails)
            ['linpla_ord'] (list)      : order list of planes/lines
        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if permpar.multcomp:
        raise ValueError('Multiple comparisons not implemented for this '
                         'analysis.')
    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('For surplock or reglock analysis, stimpar.pre and '
                         'stimpar.post must be the same.')
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
    if parallel:
        outs = Parallel(n_jobs=n_jobs)(delayed(surp_diff_by_sesses)(sessions, 
                        analyspar, stimpar, permpar, datatype, surp, baseline)
                        for sessions in linpla_sess)
    else:
        outs = []
        for sessions in linpla_sess:
            outs.append(surp_diff_by_sesses(sessions, analyspar, stimpar, 
                                        permpar, datatype, surp, baseline))
    outs = [list(out) for out in zip(*outs)]

    [mouse_diff_st, all_diff_st, all_CI_vals, all_sign_sess, sess_info] = outs

    diff_info = {'all_diff_stats'  : all_diff_st,
                 'mouse_diff_stats': mouse_diff_st,
                 'CI_vals'         : all_CI_vals,
                 'sign_sess'       : all_sign_sess,
                 'linpla_ord'      : linpla_order
                 }

    return diff_info, sess_info


#############################################
def run_surp_area_diff(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                       permpar, figpar, datatype='roi', parallel=False):
    """
    run_surp_area_diff(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                       permpar, figpar)

    Retrieves area values by session x surp val and plots statistics across 
    ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
                                            sesspar.plane, stimpar.bri_dir, 
                                            stimpar.bri_size, stimpar.gabk,
                                            'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                                            datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise - regular locked {datastr} '
          f'responses \n({sessstr_pr}{dendstr_pr}).')

    if permpar.multcomp:
        print('NOTE: Multiple comparisons not implemented for this analysis. '
              'Setting to False.')
        permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'multcomp', False)

    diff_info, sess_info = surp_diff_by_linpla(sessions, analyspar, stimpar, 
                                               permpar, datatype, surp='bysurp', 
                                               baseline=basepar.baseline, 
                                               parallel=parallel)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar': analyspar._asdict(),
            'sesspar'  : sesspar._asdict(),
            'stimpar'  : stimpar._asdict(),
            'basepar'  : basepar._asdict(),
            'permpar'  : permpar._asdict(),
            'extrapar' : extrapar,
            'sess_info': sess_info,
            'diff_info': diff_info
            }

    fulldir, savename = acr_sess_plots.plot_surp_area_diff(figpar=figpar, 
                                                           **info)
    file_util.saveinfo(info, savename, fulldir, 'json')

      
#############################################
def run_lock_area_diff(sessions, analysis, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar, datatype='roi', parallel=False):
    """
    run_lock_area_diff(sessions, analysis, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar)

    Retrieves area values by session x surp val, locked to surprise onset and 
    plots statistics across ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
                                            sesspar.plane, stimpar.bri_dir, 
                                            stimpar.bri_size, stimpar.gabk,
                                            'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                                            datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise - regular {datastr} responses '
          f' \n({sessstr_pr}{dendstr_pr}).')

    if permpar.multcomp:
        print('NOTE: Multiple comparisons not implemented for this analysis. '
              'Setting to False.')
        permpar = sess_ntuple_util.get_modif_ntuple(permpar, 'multcomp', False)

    if stimpar.pre != stimpar.post:
        print(f'WARNING: stimpar.post {stimpar.post} will be used for '
              'pre and post.')
        stimpar = sess_ntuple_util.get_modif_ntuple(stimpar, 'pre', 
                                   stimpar.post)
    
    all_diff_info = []
    all_sess_info = []
    for lock in ['surplock', 'reglock']:
        diff_info, sess_info = surp_diff_by_linpla(sessions, analyspar, stimpar, 
                                          permpar, datatype, surp=lock, 
                                          baseline=basepar.baseline, 
                                          parallel=parallel)
        all_diff_info.append(diff_info)
        all_sess_info.append(sess_info)

    extrapar = {'analysis': analysis,
                'datatype': datatype
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'permpar'   : permpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'diff_info' : all_diff_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_area_diff(figpar=figpar, 
                                       **info)
    file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def surp_traces_by_sesses(sessions, analyspar, stimpar, datatype='roi', 
                          surp='bysurp', baseline=0.1):
    """
    surp_traces_by_sesses(sessions, analyspar, stimpar)
    
    Returns dictionary containing surprise and regular sequence information, as 
    well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp': all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock': first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1

    Returns:       
        - trace_st (list)        : trace statistics, structured as
                                   session x reg/surp x frame x stats
                                   (or surp/reg if surp == 'reglock')
        - xran (list)            : second values for each frame
        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if len(sessions) == 0:
        raise ValueError('At least one session must be passed.') 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise ValueError('There should be the same number of sessions for '
                         'each mouse.')
    n_sess = n_sess[0]

    axes = [0] # to take mean/med
    if datatype == 'roi':
        axes = [1, 0]

    sess_info = []
    traces = []
    for m_sess in sessions:
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(m_sess, analyspar.fluor, 
                                    add_none=True)
        nan_idx = []
        mouse_traces = []
        for s, sess in enumerate(m_sess):
            if sess is None:
                nan_idx.append(s)
                continue
            # reg, surp [x ROI] x seq x frames
            data_arr = surp_data_by_sess(sess, analyspar, stimpar, 
                                 datatype=datatype, stats=analyspar.stats, 
                                 surp=surp, baseline=baseline)
            # get reg, surp x frames
            for d in range(len(data_arr)):
                for axis in axes:
                    data_arr[d] = math_util.mean_med(data_arr[d], 
                                    stats=analyspar.stats, axis=axis)
            mouse_traces.append(data_arr)
        sess_info.append(m_sess_info)
        mouse_traces = np.asarray(mouse_traces)
        for i in nan_idx: # add NaNs back in for appropriate sessions
            mouse_traces = np.insert(mouse_traces, i, np.nan, axis=0)
        traces.append(mouse_traces)
    # stats x sess x reg/surp x frames
    trace_st = math_util.get_stats(np.asarray(traces), 
                            stats=analyspar.stats, error=analyspar.error, 
                            axes=0, nanpol='omit')
    n_fr = trace_st.shape[-1]
    trace_st = np.transpose(trace_st, [1, 2, 3, 0]).tolist()

    pre = stimpar.pre
    if surp in ['surplock', 'reglock']:
        pre = 0
    xran = np.linspace(-pre, stimpar.post, n_fr).tolist()

    return trace_st, xran, sess_info


#############################################
def surp_traces_by_linpla(sessions, analyspar, stimpar, datatype='roi', 
                          surp='bysurp', baseline=0.1, parallel=False):
    """
    surp_traces_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing difference between surprise and regular 
    sequence information, as well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., 'roi', 'run')
                                  default: 'roi'
        - surp (str)            : how to split surprise vs reg data, either 
                                  'bysurp'  : all reg vs all surp, or
                                  'surplock': first surp, vs preceeding reg, or
                                  'reglock' : first reg, vs preceeding surp
                                  default: 'bysurp'
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline for bysurp data
                                  default: 0.1
        - parallel (bool)       : if True, sessions are initialized in parallel 
                                  across CPU cores 
                                  default: False

    Returns:
        - trace_info (dict)      : dictionary with difference info
            ['linpla_ord'] (list) : order list of planes/lines            
            ['trace_stats'] (list): trace statistics, structured as
                                    plane/line x session x reg/surp x frame 
                                               x stats
                                    (or surp/reg if surp == 'reglock')
            ['xran'] (list)       : second values for each frame
        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ['mouse_ns'] (list)   : mouse numbers
            ['sess_ns'] (list)    : session numbers  
            ['lines'] (list)      : mouse lines
            ['planes'] (list)     : imaging planes
            ['nrois'] (list)      : number of ROIs in session
            ['nanrois'] (list)    : list of ROIs with NaNs/Infs in raw traces
            ['nanrois_dff'] (list): list of ROIs with NaNs/Infs in dF/F traces, 
                                    for sessions for which this attribute 
                                    exists
    """

    if surp in ['surplock', 'reglock'] and stimpar.pre != stimpar.post:
        raise ValueError('For surplock or reglock analysis, stimpar.pre and '
                         'stimpar.post must be the same.')

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    n_jobs = gen_util.get_n_jobs(len(linpla_sess), parallel=parallel)
    if parallel:
        outs = Parallel(n_jobs=n_jobs)(delayed(surp_traces_by_sesses)(sessions, 
                        analyspar, stimpar, datatype, surp, baseline)
                        for sessions in linpla_sess)
    else:
        outs = []
        for sessions in linpla_sess:
            outs.append(surp_traces_by_sesses(sessions, analyspar, stimpar, 
                                              datatype, surp, baseline))
    outs = [list(out) for out in zip(*outs)]

    [all_trace_stats, xrans, sess_info] = outs    

    trace_info = {'xran'       : xrans[0],
                  'trace_stats': all_trace_stats,
                  'linpla_ord' : linpla_order
                  }

    return trace_info, sess_info


#############################################
def run_surp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar, datatype='roi', parallel=False):
    """
    run_surp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar)

    Retrieves area values by session x surp val and plots statistics across 
    ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
                                            sesspar.plane, stimpar.bri_dir, 
                                            stimpar.bri_size, stimpar.gabk,
                                            'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                                            datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise v regular {datastr} traces '
          f' \n({sessstr_pr}{dendstr_pr}).')

    trace_info, sess_info = surp_traces_by_linpla(sessions, analyspar, 
                                stimpar, datatype, surp='bysurp', 
                                baseline=basepar.baseline, parallel=parallel)

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : sess_info,
            'trace_info': trace_info
            }

    fulldir, savename = acr_sess_plots.plot_surp_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')

      
#############################################
def run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar, datatype='roi', parallel=False):
    """
    run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar)

    Retrieves area values by session x surp val, locked to surprise, then 
    regular onset and plots statistics across ROIs of difference between 
    regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
                                            sesspar.plane, stimpar.bri_dir, 
                                            stimpar.bri_size, stimpar.gabk,
                                            'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                                            datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    print(f'\nAnalysing and plotting surprise v regular locked {datastr} '
          f'traces \n({sessstr_pr}{dendstr_pr}).')

    if stimpar.pre != stimpar.post:
        print(f'WARNING: stimpar.post {stimpar.post} will be used for '
              'pre and post.')
        stimpar = sess_ntuple_util.get_modif_ntuple(stimpar, 'pre', 
                                   stimpar.post)

    all_sess_info = []
    all_trace_info = []
    for lock in ['surplock', 'reglock']:
        trace_info, sess_info = surp_traces_by_linpla(sessions, analyspar, 
                                    stimpar, datatype, surp=lock, 
                                    baseline=basepar.baseline, 
                                    parallel=parallel)
        all_sess_info.append(sess_info)
        all_trace_info.append(trace_info)
        

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'basepar'   : basepar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'trace_info': all_trace_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def get_rise_latency(data_arr, xran, method='ttest', p_val_thr=0.005, 
                     stats='mean', rel_std=0.5):
    """
    get_rise_latency(data_arr, xran)

    Returns rise latency values for each item (e.g., ROI) to reach threshold.

    Required args:
        - data_arr (3D array): data array, structured as 
                               item (e.g., ROI) x sequences x frames
        - xran (list)        : latency values in seconds for each frame

    Optional args:
        - method (str)     : method to use to determine latency
                             'ttest': first point higher than start point that 
                                      reaches p-value
                             'ratio': first point higher than start point by a 
                                      certain ratio of standard deviations 
                             default: 'ttest'
        - p_val_thr (float): threshold p value to use for t-test method
                             default: 0.005 
        - stats (str)      : statistic to take for starting point for ratio 
                             method
                             default: 'mean'
        - rel_std (float)  : threshold standard deviation ratio to use to for 
                             ratio method
                             default: 0.5

    Returns:
        - lat_vals (list): latency values (for all items that reach threshold 
                           for a peak latency to be determined)
        - roi_ns (list)  : numbers of ROIs that reached threshold
    """

    if method == 'ratio':
        data_st = math_util.get_stats(data_arr, stats=stats, 
                            error='std', axes=1, nanpol='omit')
        med = data_st[0]
        stat_dev = data_st[1, :, 0:1]
        rat = (med - med[:, 0:1])/stat_dev # rel strength of signal                    
    
    roi_ns = []
    lat_vals = []
    for r in range(len(data_arr)):
        if method == 'ratio':
            r_idx = np.argmax(rat[r] > rel_std)
        elif method == 'ttest':
            r_idx = 0 
            for p in range(1, data_arr.shape[-1]):
                t_stat, p_val = scist.ttest_rel(data_arr[r, :, 0], 
                                      data_arr[r, :, p], axis=None)
                if t_stat > 0 and p_val < p_val_thr:
                    r_idx = p
                    break
        else:
            gen_util.accepted_values_error('method', method, ['ratio', 'ttest'])
        if r_idx == 0: # if never peaks, skips to nan
            continue
        else:
            roi_ns.append(r)
            lat_vals.append(xran[r_idx])

    return lat_vals, roi_ns


#############################################
def comp_lat_acr_sesses(lat_vals, normal=True):
    """
    comp_lat_acr_sesses(lat_vals)

    Returns p values for comparisons across sessions with planes/lines.

    Required args:
        - lat_vals (list): latency values for each session 

    Optional args:
        - normal (bool): whether data is expected to be normal or not
                         default: True

    Returns:
        - p_vals (1D array): p values for each comparison, organized by 
                             session pairs (where the second session is cycled 
                             in the inner loop, e.g., 0-1, 0-2, 1-2, including 
                             None sessions) 
    """

    n_comp = sum(range(len(lat_vals)))
    p_vals = np.full(n_comp, np.nan)
    i = 0
    for s, s_vals in enumerate(lat_vals):
        for v_vals in lat_vals[s + 1:]:
            if s_vals is not None and v_vals is not None:
                if normal:
                    p_vals[i] = scist.ttest_ind(s_vals, v_vals, 
                                                axis=None)[1]
                else:
                    p_vals[i] = scist.mannwhitneyu(s_vals, v_vals,)[1]
            i += 1
    
    return p_vals


#############################################
def comp_lat_acr_planes(linpla_ord, lat_vals):
    """
    comp_lat_acr_planes(linpla_ord, lat_vals)

    Returns p values for comparisons across planes within lines.

    Required args:
        - linpla_ord (list): ordered list of planes/lines
        - lat_vals (list)  : latency values, structured as 
                             planes/lines x session 

    Returns:
        - p_vals (2D array): p values, structured as 
                             planes/lines x session
    """

    lines = ['L2/3', 'L5']
    n_sess = len(lat_vals[0])
    p_vals = np.full([len(lines), n_sess], np.nan)
    for li, line in enumerate(lines):
        idx = [i for i in range(len(linpla_ord)) if line in linpla_ord[i]]
        # do comparison
        if len(idx) == 2:
            for s in range(n_sess):
                # check for nans:
                data = [lat_vals[i][s] for i in idx]
                if np.min(len(d) for d in data) != 0:
                    p_vals[li, s] = scist.ttest_ind(data[0], data[1], 
                                                    axis=None)[1]

    return p_vals


#############################################
def get_sess_latencies(sess, analyspar, stimpar, datatype='roi', 
                       method='ttest', p_val_thr=0.005, rel_std=0.5):
    """
    get_sess_latencies(sess, analyspar, stimpar)

    Returns latency values for the session.

    Required args:
        - sess (Session object): session object (can be None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
    
    Optional args:
        - datatype (str)   : type of data (e.g., 'roi', 'run')
                             default: 'roi'
        - method (str)     : method for determining peak latency
                             default: 'ttest' 
        - p_val_thr (float): threshold p value to use for t-test method
                             default: 0.005 
        - rel_std (float)  : threshold standard deviation ratio to use to for 
                             ratio method
                             default: 0.5

    Returns:
        - lat_vals (list): latency values for the session or None if no session 
        - roi_ns (list)  : numbers of ROIs that reached threshold

    """

    if sess is None:
        return None
    stim = sess.get_stim(stimpar.stimtype)
    remconsec = (stimpar.stimtype == 'bricks')
    segs = stim.get_segs_by_criteria(gabfr=stimpar.gabfr, gabk=stimpar.gabk, 
                gab_ori=stimpar.gab_ori, bri_dir=stimpar.bri_dir, 
                bri_size=stimpar.bri_size, surp=1, by='seg', 
                remconsec=remconsec)
    if datatype == 'roi':
        twop_fr = stim.get_twop_fr_by_seg(segs, first=True)
        # array: ROI x sequences x frames
        xran, data_arr = stim.get_roi_trace_array(twop_fr, stimpar.pre, 
                              stimpar.post, fluor=analyspar.fluor, 
                              remnans=analyspar.remnans, stand=False, smooth=3)         
    elif datatype == 'run':
        # array: 1 x sequences x frames
        stim_fr = stim.get_stim_fr_by_seg(segs, first=True)
        xran, data_arr = stim.get_run_array(stim_fr, stimpar.pre, 
                              stimpar.post, remnans=analyspar.remnans, 
                              stand=False)
        np.expand_dims(data_arr, 0)
    else:
        gen_util.accepted_values_error('datatype', datatype, ['run', 'roi'])

    lat_vals, roi_ns = get_rise_latency(data_arr, xran, method=method, 
                                p_val_thr=p_val_thr, stats=analyspar.stats, 
                                rel_std=rel_std)

    return lat_vals, roi_ns


#############################################
def run_surp_latency(sessions, analysis, analyspar, sesspar, stimpar, latpar,
                     figpar, datatype='roi', parallel=False):
    """
    run_surp_latency(sessions, analysis, analyspar, sesspar, stimpar, 
                     figpar)

    Retrieves area values by session x surp val, locked to surprise onset and 
    plots statistics across ROIs of difference between regular and surprise.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 't')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
                                            sesspar.plane, stimpar.bri_dir, 
                                            stimpar.bri_size, stimpar.gabk,
                                            'print')
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                                            datatype, 'print')
       
    datastr = sess_str_util.datatype_par_str(datatype)

    stat_len = 2 + (analyspar.error == 'std')

    print(f'\nAnalysing and plotting surprise latency for {datastr} traces '
          f' \n({sessstr_pr}{dendstr_pr}).')

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)

    [all_lat_stats, all_lat_vals, 
     all_lat_p_vals, all_lat_vals_flat] = [], [], [], []
    all_sess_info = []

    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_lat_vals, l_lat_vals_flat, l_sess_info = [], [], []
        l_lat_stats = np.full([stat_len, len(l_sesses)], np.nan)
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(sesses, 
                                             analyspar.fluor, add_none=True))
            # for each mouse
            n_jobs = gen_util.get_n_jobs(len(l_sesses), parallel=parallel)
            if parallel:
                sess_vals = Parallel(n_jobs=n_jobs)(delayed(
                                     get_sess_latencies)(sess, analyspar, 
                                     stimpar, datatype, latpar.method, 
                                     latpar.p_val_thr, latpar.rel_std) 
                                     for sess in sesses)
                sess_lat_vals = [vals[0] for vals in sess_vals]
            else:
                sess_lat_vals = []
                for sess in sesses:
                    sess_lat_vals.append(get_sess_latencies(sess, analyspar, 
                                         stimpar, datatype, latpar.method, 
                                         latpar.p_val_thr, latpar.rel_std)[0])

            # all values across mice for the session
            lat_vals_flat = np.asarray([val for sub_vals in sess_lat_vals 
                                            if sub_vals is not None
                                            for val in sub_vals])
            l_lat_stats[:, s] = math_util.get_stats(lat_vals_flat, 
                                          analyspar.stats, analyspar.error, 
                                          nanpol='omit')
            l_lat_vals_flat.append(lat_vals_flat)
            l_lat_vals.append(sess_lat_vals)

        p_vals = comp_lat_acr_sesses(l_lat_vals_flat, normal=True).tolist()

        all_sess_info.append(l_sess_info)
        all_lat_stats.append(l_lat_stats.tolist())
        all_lat_vals_flat.append(l_lat_vals_flat)
        all_lat_vals.append(l_lat_vals)
        all_lat_p_vals.append(p_vals)

    # compare across planes in a line
    lin_p_vals = comp_lat_acr_planes(linpla_ord, all_lat_vals_flat)

    p_vals = [p for all_ps in all_lat_p_vals for p in all_ps] + \
             [p for all_ps in lin_p_vals for p in all_ps]

    n_comps = np.count_nonzero(~np.isnan(p_vals))

    lat_data = {'linpla_ord': linpla_ord,
                'lat_stats' : all_lat_stats,
                'lat_vals'  : all_lat_vals,
                'lat_p_vals': all_lat_p_vals,
                'lin_p_vals': lin_p_vals.tolist(),
                'n_comps'   : n_comps,
                }

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar': analyspar._asdict(),
            'sesspar'  : sesspar._asdict(),
            'stimpar'  : stimpar._asdict(),
            'latpar'   : latpar._asdict(),
            'extrapar' : extrapar,
            'sess_info': all_sess_info,
            'lat_data' : lat_data
            }

    fulldir, savename = acr_sess_plots.plot_surp_latency(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')


#############################################
def run_resp_prop(sessions, analysis, analyspar, sesspar, stimpar, latpar,
                  figpar, datatype='roi', parallel=False):
    """
    run_resp_prop(sessions, analysis, analyspar, sesspar, stimpar, latpar,
                  figpar)

    Retrieves proportion of ROIs that show a response to surprise within a 
    limited latency for both stimuli and plots statistics across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., 'p')
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., 'roi', 'run')
                           default: 'roi'
        - parallel (bool): if True, sessions are initialized in parallel 
                           across CPU cores 
                           default: False
    """



    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
                               datatype, 'print')

    print('\nAnalysing and plotting proportion of surprise responsive ROIs'
          f'{dendstr_pr}.')

    if stimpar.stimtype != 'both':
        raise ValueError('stimpar.stimtype must be `both` for this analysis.')
    stimtypes = ['gabors', 'gabors', 'bricks']
    gabfrs    = [3, 1, 'none']
    comb_names = ['gabfrs', 'surps']
    combs      = [[0, 1] , [0, 2]]

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)

    all_sess_info = []
    all_prop_stats = []
    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_sess_info = []
        l_prop_stats = []
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(sesses, 
                                             analyspar.fluor, add_none=True))
            # keep only sessions with both stimuli
            sesses = sess_gen_util.check_both_stimuli(sesses)
            nrois = [sess.get_nrois(analyspar.remnans, analyspar.fluor) 
                                                    for sess in sesses]
            resp_arrs = [np.full([len(stimtypes), nroi], 0) for nroi in nrois]         
            for s, (stimtype, gabfr) in enumerate(zip(stimtypes, gabfrs)):
                stimpar_spec = sess_ntuple_util.get_modif_ntuple(stimpar, 
                                                ['stimtype', 'gabfr'], 
                                                [stimtype, gabfr])
                # for each mouse
                n_jobs = gen_util.get_n_jobs(len(l_sesses), parallel=parallel)
                if parallel:
                    sess_vals = Parallel(n_jobs=n_jobs)(delayed(
                                         get_sess_latencies)(sess, analyspar, 
                                         stimpar_spec, datatype, latpar.method, 
                                         latpar.p_val_thr, latpar.rel_std) 
                                         for sess in sesses)
                    sess_roi_ns = [vals[1] for vals in sess_vals]

                else:
                    sess_roi_ns = []
                    for sess in sesses:
                        sess_roi_ns.append(get_sess_latencies(sess, analyspar, 
                                        stimpar_spec, datatype, latpar.method, 
                                        latpar.p_val_thr, latpar.rel_std)[1])
                for r, roi_ns in enumerate(sess_roi_ns):
                    if len(roi_ns) > 0:
                        resp_arrs[r][s, np.asarray(roi_ns)] = 1
            resp_prop_stats = []
            for comb in combs:
                comb_props = []
                for nroi, resp_arr in zip(nrois, resp_arrs):
                    if nroi == 0:
                        continue
                    resp_same = resp_arr[comb[0]] == resp_arr[comb[1]]
                    comb_props.append(sum(resp_same)/float(nroi))
                resp_prop_me = math_util.mean_med(comb_props, 
                                         stats=analyspar.stats, nanpol='omit')
                resp_prop_de = math_util.error_stat(comb_props, 
                                         stats=analyspar.stats, 
                                         error=analyspar.error, nanpol='omit')
                resp_prop_stats.append([resp_prop_me, resp_prop_de])
            l_prop_stats.append(resp_prop_stats)
        all_prop_stats.append(l_prop_stats)
    all_sess_info.append(l_sess_info)

    prop_data = {'linpla_ord': linpla_ord,
                 'prop_stats': all_prop_stats,
                 'comb_names': comb_names
                }

    extrapar = {'analysis': analysis,
                'datatype': datatype,
                }

    info = {'analyspar' : analyspar._asdict(),
            'sesspar'   : sesspar._asdict(),
            'stimpar'   : stimpar._asdict(),
            'latpar'    : latpar._asdict(),
            'extrapar'  : extrapar,
            'sess_info' : all_sess_info,
            'prop_data' : prop_data
            }

    fulldir, savename = acr_sess_plots.plot_resp_prop(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, 'json')
