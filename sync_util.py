'''
sync_util.py

This module contains functions for synchronizing the different data files 
generated by the AIBS experiments for the Credit Assignment Project.

Authors: Allen Brain Institute, Joel Zylberberg, Blake Richards, Colleen Gillon

Date: August, 2018

Note: this code uses python 2.7.

'''

import h5py
import json
import numpy as np
import pandas as pd
import pickle
import os.path
import exceptions
from dataset import Dataset
from Dataset2p import Dataset2p

import pdb

# set a few basic parameters
ASSUMED_DELAY = 0.0351
DELAY_THRESHOLD = 0.001
FIRST_ELEMENT_INDEX = 0
SECOND_ELEMENT_INDEX = 1
SKIP_FIRST_ELEMENT = 1
ROUND_PRECISION = 4
ZERO = 0
ONE = 1
TWO = 2
MIN_BOUND = .03
MAX_BOUND = .04

###############################################################################
def calculate_stimulus_alignment(stim_time, valid_twop_vsync_fall):
    print 'calculating stimulus alignment'

    # convert stimulus frames into twop frames
    stimulus_alignment = np.empty(len(stim_time))

    for index in range(len(stim_time)):
        crossings = np.nonzero(np.ediff1d(np.sign(valid_twop_vsync_fall - stim_time[index])) > ZERO)
        try:
            stimulus_alignment[index] = int(crossings[FIRST_ELEMENT_INDEX][FIRST_ELEMENT_INDEX])
        except:
            stimulus_alignment[index] = np.NaN

    return stimulus_alignment


###############################################################################
def calculate_valid_twop_vsync_fall(sync_data, sample_frequency):
    ####microscope acquisition frames####
    # get the falling edges of 2p
    twop_vsync_fall = sync_data.get_falling_edges('2p_vsync') / sample_frequency

    if len(twop_vsync_fall) == 0:
        raise ValueError('Error: twop_vsync_fall length is 0, possible invalid, missing, and/or bad data')

    ophys_start = twop_vsync_fall[0]

    # only get data that is beyond the start of the experiment
    valid_twop_vsync_fall = twop_vsync_fall[np.where(twop_vsync_fall > ophys_start)[FIRST_ELEMENT_INDEX]]

    # skip the first element to eliminate the DAQ pulse
    return valid_twop_vsync_fall


###############################################################################
def calculate_stim_vsync_fall(sync_data, sample_frequency):
    ####stimulus frames####
    # skip the first element to eliminate the DAQ pulse
    stim_vsync_fall = sync_data.get_falling_edges('stim_vsync')[SKIP_FIRST_ELEMENT:] / sample_frequency

    return stim_vsync_fall


###############################################################################
def calculate_delay(sync_data, stim_vsync_fall, sample_frequency):
    print 'calculating delay'

    try:
        # photodiode transitions
        photodiode_rise = sync_data.get_rising_edges('stim_photodiode') / sample_frequency

        ####Find start and stop of stimulus####
        # test and correct for photodiode transition errors
        photodiode_rise_diff = np.ediff1d(photodiode_rise)
        min_short_photodiode_rise = 0.1
        max_short_photodiode_rise = 0.3
        min_medium_photodiode_rise = 0.5
        max_medium_photodiode_rise = 1.5

        # find the short and medium length photodiode rises
        short_rise_indexes = np.where(np.logical_and(photodiode_rise_diff > min_short_photodiode_rise, \
                                                     photodiode_rise_diff < max_short_photodiode_rise))[
            FIRST_ELEMENT_INDEX]
        medium_rise_indexes = np.where(np.logical_and(photodiode_rise_diff > min_medium_photodiode_rise, \
                                                      photodiode_rise_diff < max_medium_photodiode_rise))[
            FIRST_ELEMENT_INDEX]

        short_set = set(short_rise_indexes)

        # iterate through the medium photodiode rise indexes to find the start and stop indexes
        # lookng for three rise pattern
        next_frame = ONE
        start_pattern_index = 2
        end_pattern_index = 3
        ptd_start = None
        ptd_end = None

        for medium_rise_index in medium_rise_indexes:
            if set(range(medium_rise_index - start_pattern_index, medium_rise_index)) <= short_set:
                ptd_start = medium_rise_index + next_frame
            elif set(range(medium_rise_index + next_frame, medium_rise_index + end_pattern_index)) <= short_set:
                ptd_end = medium_rise_index

        # if the photodiode signal exists
        if ptd_start != None and ptd_end != None:
            # check to make sure there are no there are no photodiode errors
            # sometimes two consecutive photodiode events take place close to each other
            # correct this case if it happens
            photodiode_rise_error_threshold = 1.8
            last_frame_index = -1

            # iterate until all of the errors have been corrected
            while any(photodiode_rise_diff[ptd_start:ptd_end] < photodiode_rise_error_threshold):
                error_frames = np.where(photodiode_rise_diff[ptd_start:ptd_end] < \
                                        photodiode_rise_error_threshold)[FIRST_ELEMENT_INDEX] + ptd_start
                # remove the bad photodiode event
                photodiode_rise = np.delete(photodiode_rise, error_frames[last_frame_index])
                ptd_end -= 1
                photodiode_rise_diff = np.ediff1d(photodiode_rise)

            ####Find the delay####
            # calculate monitor delay
            first_pulse = ptd_start
            number_of_photodiode_rises = ptd_end - ptd_start
            half_vsync_fall_events_per_photodiode_rise = 60
            vsync_fall_events_per_photodiode_rise = half_vsync_fall_events_per_photodiode_rise * 2

            delay_rise = np.empty(number_of_photodiode_rises)
            for photodiode_rise_index in range(number_of_photodiode_rises):
                delay_rise[photodiode_rise_index] = photodiode_rise[photodiode_rise_index + first_pulse] - \
                                                    stim_vsync_fall[(
                                                                    photodiode_rise_index * vsync_fall_events_per_photodiode_rise) + \
                                                                    half_vsync_fall_events_per_photodiode_rise]

            # get a single delay value by finding the mean of all of the delays - skip the last
            # element in the array (the end of the experimenet)
            delay = np.mean(delay_rise[:last_frame_index])

            if (delay > DELAY_THRESHOLD or np.isnan(delay)):
                print "Sync error needs to be fixed"
                delay = ASSUMED_DELAY
                print "Using assumed delay:", round(delay, ROUND_PRECISION)

        # assume delay
        else:
            delay = ASSUMED_DELAY
    except Exception as e:
        print e
        print "Process without photodiode signal"
        delay = ASSUMED_DELAY
        print "Assumed delay:", round(delay, ROUND_PRECISION)

    return delay

###############################################################################
def get_frame_rate(syn_file_name):
    
    '''
    get_frame_times(stim_sync_file)

    Pulls out the ophys frame times stimulus sync file and returns stats for
    ophys frame rates.

    Required arguments:
        - stim_sync_file (string)    : full path name of the experiment sync hdf5 file

    Outputs:
        - twop_rate_mean: mean ophys frame rate
        - twop_rate_med: median ophys frame rate
        - twop_rate_std: standard deviation of ophys frame rate
    '''

    # create a Dataset object with the sync file
    sync_data = Dataset(syn_file_name)
   
    sample_frequency = sync_data.meta_data['ni_daq']['counter_output_freq']
    
    # calculate the valid twop_vsync fall
    valid_twop_vsync_fall = calculate_valid_twop_vsync_fall(sync_data, sample_frequency)
    twop_diff = np.diff(valid_twop_vsync_fall)
    
    twop_rate_mean = np.mean(1./twop_diff)
    twop_rate_med = np.median(1./twop_diff)
    twop_rate_std = np.std(1./twop_diff)
    
    return twop_rate_mean, twop_rate_med, twop_rate_std

###############################################################################
def get_stim_frames(pkl_file_name, syn_file_name, df_pkl_name):

    '''
    get_stim_frames(stim_pickle_file, stim_sync_file, output_pickle_file)

    Pulls out the stimulus frame information from the stimulus pickle file, as
    well as synchronization information from the stimulus sync file, and stores
    synchronized stimulus frame information in the output pickle file along with
	the stimulus alignment array.

    Required arguments:
        - stim_pickle_file (string)  : full path name of the experiment stim pickle file
        - stim_sync_file (string)    : full path name of the experiment sync hdf5 file
        - output_pickle_file (string): full path name of the output pickle file to create
    '''

    # check that the input files exist
    if not os.path.isfile(pkl_file_name):
        raise exceptions.OSError('%s does not exist' %(pkl_file_name))
    if not os.path.isfile(syn_file_name):
        raise exceptions.OSError('%s does not exist' %(syn_file_name))

    num_stimtypes = 2 #bricks and Gabors

    # read the pickle file and call it "pkl"
    with open(pkl_file_name, 'rb') as f:
        pkl = pickle.load(f)

    num_stimtypes = 2 # bricks and Gabors
    if len(pkl['stimuli']) != num_stimtypes:
        raise ValueError('{} stimuli types expected, but {} found'
                         .format(num_stimtypes, len(pkl['stimuli'])))
        
    # create a Dataset object with the sync file
    sync_data = Dataset(syn_file_name)

    # create Dataset2p object which will be used for the delay
    dset = Dataset2p(syn_file_name)

    sample_frequency = sync_data.meta_data['ni_daq']['counter_output_freq']

    # calculate the valid twop_vsync fall
    valid_twop_vsync_fall = calculate_valid_twop_vsync_fall(sync_data, sample_frequency)

    # get the stim_vsync_fall
    stim_vsync_fall = calculate_stim_vsync_fall(sync_data, sample_frequency)

    # find the delay
    # delay = calculate_delay(sync_data, stim_vsync_fall, sample_frequency)
    delay = dset.display_lag

    # adjust stimulus time with monitor delay
    stim_time = stim_vsync_fall + delay

    # find the alignment
    stimulus_alignment = calculate_stimulus_alignment(stim_time, valid_twop_vsync_fall)
    offset = int(pkl['pre_blank_sec'] *pkl['fps'])
    
    print("Creating the stim_df:")
    
    # get number of segments expected and actually recorded for each stimulus
    segs = []
    segs_exp = []
    frames_per_seg = []
    stim_types = []
    
    for i in range(num_stimtypes):
        # records the max num of segs in the frame list for each stimulus
        segs.extend([np.max(pkl['stimuli'][i]['frame_list'])+1])
        
        # calculates the expected number of segs based on fps, display duration (s) and seg length
        fps = pkl['stimuli'][i]['fps']
        
        if pkl['stimuli'][i]['stimParams']['elemParams']['name'] == 'bricks':
            stim_types.extend(['b'])
            frames_per_seg.extend([fps])
            segs_exp.extend([int(60.*np.sum(np.diff(pkl['stimuli'][i]['display_sequence']))/frames_per_seg[i])])
        elif pkl['stimuli'][i]['stimParams']['elemParams']['name'] == 'gabors':
            stim_types.extend(['g'])
            frames_per_seg.extend([fps/1000.*300])
            segs_exp.extend([int(60.*np.sum(np.diff(pkl['stimuli'][i]['display_sequence']))/frames_per_seg[i]*4./5)]) # to exclude grey seg
        else:
            raise ValueError('{} stimulus type not recognized.'.format(pkl['stimuli'][i]['stimParams']['elemParams']['name']))
        
        
        # check whether the actual number of frames is within a small range of expected
        # about two frames per sequence?
        n_seq = pkl['stimuli'][0]['display_sequence'].shape[0] * 2
        if np.abs(segs[i] - segs_exp[i]) > n_seq:
            raise ValueError('Expected {} frames for stimulus {}, but found {}.'
                             .format(segs_exp[i], i, segs[i]))
    
    total_stimsegs = np.sum(segs)
    
    stim_df = pd.DataFrame(index=range(np.sum(total_stimsegs)), columns=['stimType', 'stimPar1', 'stimPar2', 'surp', 
                                                             'stimSeg', 'GABORFRAME', 'start_frame', 'end_frame', 'num_frames'])
    
    zz = 0
    # For gray-screen pre_blank
    stim_df.ix[zz, 'stimType'] = -1
    stim_df.ix[zz, 'stimPar1'] = -1
    stim_df.ix[zz, 'stimPar2'] = -1
    stim_df.ix[zz, 'surp'] = -1
    stim_df.ix[zz, 'stimSeg'] = -1
    stim_df.ix[zz, 'GABORFRAME'] = -1
    stim_df.ix[zz, 'start_frame'] = stimulus_alignment[0]
    stim_df.ix[zz, 'end_frame'] = stimulus_alignment[offset]
    stim_df.ix[zz, 'num_frames'] = stimulus_alignment[offset] - stimulus_alignment[0]
    zz += 1

    for stype in range(num_stimtypes):
        print('stimtype:', stype)
        movie_segs = pkl['stimuli'][stype]['frame_list']

        tf = 0
        for segment in range(segs[stype]):
            seg_inds = np.where(movie_segs == segment)[0]
            tup = (segment, int(stimulus_alignment[seg_inds[0] + offset]), \
                   int(stimulus_alignment[seg_inds[-1] + 1 + offset]))

            stim_df.ix[zz, 'stimType'] = stype
            stim_df.ix[zz, 'stimSeg'] = segment
            stim_df.ix[zz, 'start_frame'] = tup[1]
            stim_df.ix[zz, 'end_frame'] = tup[2]
            stim_df.ix[zz, 'num_frames'] = tup[2] - tup[1]

            if stim_types[stype] == 'b':
                stim_df.ix[zz, 'stimPar1'] = pkl['stimuli'][0]['stimParams']['subj_params']['flipdirecarray'][segment][1] #big or small
                stim_df.ix[zz, 'stimPar2'] = pkl['stimuli'][0]['stimParams']['subj_params']['flipdirecarray'][segment][3] #L or R
                stim_df.ix[zz, 'surp'] = pkl['stimuli'][0]['stimParams']['subj_params']['flipdirecarray'][segment][0] #SURP
                stim_df.ix[zz, 'GABORFRAME'] = -1
            
            if stim_types[stype] == 'g':
                stim_df.ix[zz, 'stimPar1'] = pkl['stimuli'][1]['stimParams']['subj_params']['oriparsurps'][int(np.floor(segment/4))][0] #angle
                stim_df.ix[zz, 'stimPar2'] = pkl['stimuli'][1]['stimParams']['subj_params']['oriparsurps'][int(np.floor(segment/4))][1] #angular var
                stim_df.ix[zz, 'surp'] = pkl['stimuli'][1]['stimParams']['subj_params']['oriparsurps'][int(np.floor(segment/4))][2] #SURP
                stim_df.ix[zz, 'GABORFRAME'] = np.mod(tf,4)

            zz += 1
            tf += 1
            
    # check whether any 2P frames are in associated to 2 stimuli
    overlap = np.any((np.sort(stim_df['start_frame'])[1:] - 
                     np.sort(stim_df['end_frame'])[:-1]) < 0)
    if overlap:
        raise ValueError('Some 2P frames associated with two stimulus \
                         segments.')
	
    # create a dictionary for pickling
    stim_dict = {'stim_df': stim_df, 'stim_align': stimulus_alignment}   
 
    # store in the pickle file
    try:
        with open(df_pkl_name, "wb") as f:
            pickle.dump(stim_dict,f)
    except:
        raise exceptions.IOError("Could not save stimulus pickle file {}".format(df_pkl_name))  
    #stim_df.to_pickle(df_pkl_name)

###############################################################################
def get_run_speed(pkl_file_name):

    '''
    get_run_speed(stim_pickle_file)

    Pulls out the running speed information from the stim pickle file, returns
    as a numpy array. Note: the length of the array is equivalent to the array
    returned by get_stimulus_frames. The running speed provided corresponds
    to the speed at each stimulus frame. Thus, aligning to the 2p data can be
    done using the stimulus_alignment array.

    Required arguments:
        - stim_pickle_file (string)  : full path name of the experiment stim pickle file

    Outputs:
        - running_speed (array): array of length equal to the number of stimulus
                                 frames, each element indicates running speed for
                                 that stimulus frame
    '''
    # check that the input file exists
    if not os.path.isfile(pkl_file_name):
        raise exceptions.OSError('%s does not exist' %(pkl_file_name))

    # read the input pickle file and call it "pkl"
    with open(pkl_file_name, 'rb') as f:
        pkl = pickle.load(f)

    # determine the running wheel radius in cm
    # TO-DO: ASK JEROME WHERE THIS IS HARD-CODED
    wheel_radius = 5.5036

    # determine the frames per second of the running wheel recordings
    fps = pkl['fps']

    # determine the change in angle during each frame
    dtheta = pkl['items']['foraging']['encoders'][0]['dx']

    # calculate the running speed (skip first element, since it is ignored in stimulus frames as well)
    # TO-DO: skip last instead as this was a mistake pointed out by Jed.
    runspeed = dtheta[SKIP_FIRST_ELEMENT:] * fps * (2.0 * np.pi * wheel_radius / 360.0)

    return runspeed
