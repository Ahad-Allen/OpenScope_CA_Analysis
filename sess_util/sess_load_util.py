"""
sess_load_util.py

This module contains functions for loading data from files generated by the 
AIBS experiments for the Credit Assignment Project.

Authors: Blake Richards

Date: August, 2018

Note: this code uses python 3.7.

"""

import copy
import os

import h5py
import numpy as np
import pandas as pd
import pickle
from allensdk.brain_observatory import dff

from util import file_util, gen_util
from sess_util import sess_sync_util


######################################
def load_info_from_mouse_df(sessid, mouse_df='mouse_df.csv'):
    """
    load_info_from_mouse_df(sessid)

    Returns dictionary containing information from the mouse dataframe.

    Required args:
        - sessid (int): session ID

    Optional args:
        - mouse_df (str): path name of dataframe containing information on each 
                          session. Dataframe should have the following columns:
                              sessid, mouse_n, depth, plane, line, sess_gen, 
                              sess_within, sess_n, pass_fail, all_files, 
                              any_files, notes
                          default: 'mouse_df.csv'

    Returns:
        - df_dict (dict): dictionary with following keys:
            - all_files (bool) : if True, all files have been acquired for
                                 the session
            - any_files (bool) : if True, some files have been acquired for
                                 the session
            - depth (int)      : recording depth 
            - plane (str)      : recording plane ('soma' or 'dend')
            - line (str)       : mouse line (e.g., 'L5-Rbp4')
            - mouse_n (int)    : mouse number (e.g., 1)
            - notes (str)      : notes from the dataframe on the session
            - pass_fail (str)  : whether session passed 'P' or failed 'F' 
                                 quality control
            - sess_gen (int)   : general session number (e.g., 1)
            - sess_within (int): within session number (session number within
                                 the sess_gen) (e.g., 1)
            - sess_n (int)     : overall session number (e.g., 1)
    """

    if isinstance(mouse_df, str):
        mouse_df = file_util.loadfile(mouse_df)

    df_line = gen_util.get_df_vals(mouse_df, 'sessid', sessid)

    df_dict = {
        'mouse_n'      : int(df_line['mouse_n'].tolist()[0]),
        'depth'        : df_line['depth'].tolist()[0],
        'plane'        : df_line['plane'].tolist()[0],
        'line'         : df_line['line'].tolist()[0],
        'sess_gen'     : int(df_line['sess_gen'].tolist()[0]),
        'sess_n'       : int(df_line['sess_n'].tolist()[0]),
        'sess_within'  : int(df_line['sess_within'].tolist()[0]),
        'pass_fail'    : df_line['pass_fail'].tolist()[0],
        'all_files'    : bool(int(df_line['all_files'].tolist()[0])),
        'any_files'    : bool(int(df_line['any_files'].tolist()[0])),
        'notes'        : df_line['notes'].tolist()[0],
    }

    return df_dict


#############################################
def load_small_stim_pkl(stim_pkl, runtype='prod'):
    """
    load_small_stim_pkl(stim_pkl)

    Loads a smaller stimulus dictionary from the stimulus pickle file in which 
    'posbyframe' for bricks stimuli is not included. 
    
    If it does not exist, small stimulus dictionary is created and saved as a
    pickle with '_small' appended to name.
    
    Reduces the pickle size about 10 fold.

    Required args:
        - stim_pkl (str): full path name for the full stimulus
                          pickle file
    
    Optional args:
        - runtype (str): runtype ('prod' or 'pilot')
    """

    stim_pkl_no_ext = os.path.splitext(stim_pkl)[0]
    small_stim_pkl_name = f'{stim_pkl_no_ext}_small.pkl'
    
    if os.path.exists(small_stim_pkl_name):
        return file_util.loadfile(small_stim_pkl_name)
    else:
        print('    Creating smaller stimulus pickle.')

        if isinstance(stim_pkl, str):
            stim_dict = file_util.loadfile(stim_pkl)
        else:
            stim_dict = copy.deepcopy(stim_dict)

        if runtype == 'pilot':
            stim_par_key = 'stimParams'
        elif runtype == 'prod':
            stim_par_key = 'stim_params'
        else:
            gen_util.accepted_values_error('runtype', runtype, 
                                           ['prod', 'pilot'])

        for i in range(len(stim_dict['stimuli'])):
            stim_keys = stim_dict['stimuli'][i][stim_par_key].keys()
            stim_par = stim_dict['stimuli'][i][stim_par_key]
            if runtype == 'pilot' and 'posByFrame' in stim_keys:
                _ = stim_par.pop('posByFrame')
            elif runtype == 'prod' and 'square_params' in stim_keys:
                _ = stim_par['session_params'].pop('posbyframe')
                
        file_util.saveinfo(stim_dict, small_stim_pkl_name)

        return stim_dict


#############################################
def load_stim_df_info(stim_pkl, stim_sync_h5, align_pkl, sessdir, 
                      runtype='prod'):
    """
    load_stim_df_info(stim_pkl, align_pkl, stim_sync_h5)

    Creates the alignment dataframe (stim_df) and saves it as a pickle
    in the session directory, if it does not already exist. Returns dataframe, 
    alignment arrays, and frame rate.
    
    Required args:
        - stim_pkl (str)    : full path name of the experiment stim pickle 
                              file
        - align_pkl (str)   : full path name of the output pickle file to 
                              create
        - stim_sync_h5 (str): full path name of the experiment sync hdf5 file
        - sessdir (str)     : session directory

    Optional args:
        - runtype (str): runtype ('prod' or 'pilot')
                         default: 'prod'

    Returns:
        - stim_df (pd DataFrame): stimlus alignment dataframe with columns:
                                    'stimType', 'stimPar1', 'stimPar2', 
                                    'surp', 'stimSeg', 'gabfr', 
                                    'start2pfr', 'end2pfr', 'num2pfr'
        - stim2twopfr (1D array): 2p frame numbers for each stimulus frame, 
                                  as well as the flanking
                                  blank screen frames 
        - twop_fps (num)        : mean 2p frames per second
        - twop_fr_stim (int)    : number of 2p frames recorded while stim
                                  was playing
        - twop2stimfr (1D array): stimulus frame numbers for the beginning
                                  of each 2p frame (np.nan when no stimulus
                                  appears)
    """

    # create stim_df if doesn't exist
    if not os.path.exists(align_pkl):
        sess_sync_util.get_stim_frames(stim_pkl, stim_sync_h5, align_pkl, 
                                       runtype)
        
    else:
        print('    NOTE: Stimulus alignment pickle already exists in '
                f'{sessdir}')

    align = file_util.loadfile(align_pkl)

    stim_df = align['stim_df']
    stim_df = stim_df.rename(columns={'GABORFRAME': 'gabfr', 
                                      'start_frame': 'start2pfr', 
                                      'end_frame': 'end2pfr', 
                                      'num_frames': 'num2pfr'})

    stim_df = modify_bri_segs(stim_df, runtype)

    stim2twopfr  = align['stim_align'].astype('int')
    twop_fps     = sess_sync_util.get_frame_rate(stim_sync_h5)[0] 
    twop_fr_stim = int(max(align['stim_align']))
    
    return stim_df, stim2twopfr, twop_fps, twop_fr_stim


#############################################
def load_run_data(stim_dict, diff_thr=100):
    """
    load_run_data(stim_dict)

    Returns running velocity with outliers replaced with NaNs.

    Required args:
        - stim_dict (str or dict): stimulus dictionary or path to dictionary,
                                   containing stimulus information

    Optional args:
        - diff_thr (int): threshold of difference in running velocity to 
                          identify outliers
                          default: 100

    Returns:
        - run (1D array): array of running velocities in cm/s for each 
                          recorded stimulus frames

    """

    # identify outliers by identifying unusual changes in running velocity
    if isinstance(stim_dict, dict):
        run = sess_sync_util.get_run_velocity(stim_dict=stim_dict)
    elif isinstance(stim_dict, str):
        run = sess_sync_util.get_run_velocity(pkl_file_name=stim_dict)
    else:
        raise ValueError('`stim_dict` must be a dictionary or a path to a '
                         'pickle.')
                        
    run_diff = np.diff(run)
    out_idx = np.where((run_diff < -diff_thr) | (run_diff > diff_thr))[0]
    if len(out_idx) > 0:
        print(f'    WARNING: {len(out_idx)} running values were '
               'replaced with NaNs.')
    at_idx = -1
    for idx in out_idx:
        if idx > at_idx:
            orig = idx
            if idx == 0:
                # in case the first value is completely off
                comp_val = 0
                if np.absolute(run[0]) > diff_thr:
                    run[0] = np.nan
                    orig = -1
            else:
                comp_val = run[idx]
            while np.absolute(run[idx + 1] - comp_val) > diff_thr:
                run[idx + 1] = np.nan
                idx += 1
            if idx - orig > 5:
                print(f'    WARNING: {idx-orig} consecutive running '
                       'values had to be dropped.')
            at_idx = idx

    return run


#############################################
def load_pup_data(pup_data_h5):
    """
    load_pup_data(pup_data_h5)

    If it exists, loads the pupil tracking data. Extracts pupil diameter
    and position information in pixels.

    If it doesn't exist or several are found, raises an error.

    Required args:
        - pup_data_h5 (str or list): path to the pupil data h5 file

    Returns:
        - pup_diam (1D array)    : median pupil diameter in pixels
        - pup_center_x (1D array): pupil center position for x at 
                                   each pupil frame in pixels
        - pup_center_y (1D array): pupil center position for y at 
                                   each pupil frame in pixels
    """

    print('Loading pupil tracking information.')
    if pup_data_h5 == 'none':
        raise OSError('No pupil data file found.')
    elif isinstance(pup_data_h5, list):
        raise OSError('Many pupil data files found.')

    pup_data = pd.read_hdf(pup_data_h5)
    
    pup_diam = pup_data['nan_diam'].to_numpy()
    pup_center_x = pup_data['nan_center_x'].to_numpy()
    pup_center_y = pup_data['nan_center_y'].to_numpy()

    return pup_diam, pup_center_x, pup_center_y    


#############################################
def load_sync_h5_data(pup_video_h5, time_sync_h5):
    """
    load_sync_h5_data(pup_video_h5, time_sync_h5)

    Returns pupil and behaviour synchronization information.

    Required args:
        - pup_video_h5 (str): path to the pupil video h5 file
        - time_sync_h5 (str): path to the time synchronization hdf5 file

    Returns:
        - pup_fr_interv (1D array): interval in sec between each pupil 
                                    frame
        - twop2bodyfr (1D array)  : body-tracking video (video-0) frame 
                                    numbers for each 2p frame
        - twop2pupfr (1D array)   : eye-tracking video (video-1) frame 
                                    numbers for each 2p frame
        - stim2twopfr2 (1D array) : 2p frame numbers for each stimulus 
                                    frame, as well as the flanking
                                    blank screen frames (second 
                                    version, very similar to stim2twopfr 
                                    with a few differences)
    """

    with h5py.File(pup_video_h5, 'r') as f:
        pup_fr_interv = f['frame_intervals'].value.astype('float64')

    with h5py.File(time_sync_h5, 'r') as f:
        twop2bodyfr  = f['body_camera_alignment'].value.astype('int')
        twop2pupfr   = f['eye_tracking_alignment'].value.astype('int')
        stim2twopfr2 = f['stimulus_alignment'].value.astype('int')

    return pup_fr_interv, twop2bodyfr, twop2pupfr, stim2twopfr2


#############################################
def modify_bri_segs(stim_df, runtype='prod'):
    """
    modify_bri_segs(stim_df)

    Returns stim_df with brick segment numbers modified to ensure that
    they are different for the two brick stimuli in the production data.

    Required args:
        - stim_df (pd DataFrame): stimlus alignment dataframe with columns:
                                    'stimType', 'stimPar1', 'stimPar2', 
                                    'surp', 'stimSeg', 'gabfr', 
                                    'start2pfr', 'end2pfr', 'num2pfr'

    Optional args:
        - runtype (str): runtype

    Returns:
        - stim_df (pd DataFrame): modified dataframe
    """

    if runtype != 'prod':
        return stim_df

    stim_df = copy.deepcopy(stim_df)

    bri_st_fr = gen_util.get_df_vals(stim_df, 'stimType', 'b', 
                                        'start2pfr', unique=False)
    bri_num_fr = np.diff(bri_st_fr)
    num_fr = gen_util.get_df_vals(stim_df, 'stimType', 'b', 
                                    'num2pfr', unique=False)[:-1]
    break_idx = np.where(num_fr != bri_num_fr)[0]
    n_br = len(break_idx)
    if n_br != 1:
        raise ValueError('Expected only one break in the bricks '
                         f'stimulus, but found {n_br}.')
    
    # last start frame and seg for the first brick stim
    last_fr1 = bri_st_fr[break_idx[0]] 
    last_seg1 = gen_util.get_df_vals(stim_df, ['stimType', 'start2pfr'], 
                                        ['b', last_fr1], 'stimSeg')[0]
    
    seg_idx = ((stim_df['stimType'] == 'b') & 
                (stim_df['start2pfr'] > last_fr1))

    new_idx = stim_df.loc[seg_idx]['stimSeg'] + last_seg1 + 1
    stim_df = gen_util.set_df_vals(stim_df, seg_idx, 'stimSeg', new_idx)

    return stim_df


#############################################
def create_dff(roi_trace_h5, roi_trace_dff_h5, sessid, replace=False, 
               basewin=1000):
    """
    create_dff(roi_trace_h5, roi_trace_dff_h5, sessid)

    If it doesn't exist, creates and saves dF/F trace file.

    Required args:
        - roi_trace_h5     (str): path to ROI traces
        - roi_trace_dff_h5 (str): path to dF/F ROI traces
        - sessid (int)          : session ID

    Optional args:
        - replace (bool): if True, replaces pre-existing dF/F traces. If
                            False, no new dF/F traces are created if they
                            already exist.
                            default: False
        - basewin (int) : basewin factor for compute_dff function
                            default: 1000 
    """

    if os.path.exists(roi_trace_dff_h5) and not replace:
        return

    else:
        print(f'    Creating dF/F files using {basewin} basewin '
              f'for session {sessid}')
        # read the data points into the return array
        with h5py.File(roi_trace_h5,'r') as f:
            try:
                traces = f['data'].value
            except:
                raise OSError(f'Could not read {roi_trace_h5}')
        
        traces = dff.compute_dff(traces, mode_kernelsize=2*basewin, 
                                  mean_kernelsize=basewin)
            
        with h5py.File(roi_trace_dff_h5, 'w') as hf:
            hf.create_dataset('data',  data=traces)

